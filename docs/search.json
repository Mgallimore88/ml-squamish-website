[
  {
    "objectID": "past-events/site-test/index.html",
    "href": "past-events/site-test/index.html",
    "title": "Test post linking to a notebook",
    "section": "",
    "text": "Testing the site’s ability to display jupyter notebooks.\nnotebook"
  },
  {
    "objectID": "past-events/chat-GPT-peter/index.html",
    "href": "past-events/chat-GPT-peter/index.html",
    "title": "Chat-GPT: The architecture behind the model",
    "section": "",
    "text": "There is a slideshow accompanying this section.\nSlideshow"
  },
  {
    "objectID": "past-events/numpy-peter/index.html",
    "href": "past-events/numpy-peter/index.html",
    "title": "Numpy deep dive",
    "section": "",
    "text": "numpylogo\n\n\nThis evening Peter hosted a talk on NumPy, a python numeric processing package which runs on C under the hood.\nPeter made a notebook accompanying this talk; check it out here! notebook"
  },
  {
    "objectID": "past-events/site-test/nb_with_code.html",
    "href": "past-events/site-test/nb_with_code.html",
    "title": "ML Squamish",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n\n\nThe following function describes a straight line , where m is the gradient and c is the y intercept:\n\\[\n\\large y = mx + c\n\\]\nWe can show that this equation plots a straight line by experiment: making a set of inputs x, and calculating the corresponding values of y, a function of x:\n\nx = np.linspace(0,49)\nm = 2\nc = -4\nprint(f'm = {m}, c = {c}')\n\nm = 2, c = -4\n\n\n\nx\n\narray([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,\n       39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49.])\n\n\n\ny = m*x+c\ny\n\narray([-4., -2.,  0.,  2.,  4.,  6.,  8., 10., 12., 14., 16., 18., 20.,\n       22., 24., 26., 28., 30., 32., 34., 36., 38., 40., 42., 44., 46.,\n       48., 50., 52., 54., 56., 58., 60., 62., 64., 66., 68., 70., 72.,\n       74., 76., 78., 80., 82., 84., 86., 88., 90., 92., 94.])\n\n\n\nplt.plot(x,y)\nplt.plot(x,x)\nplt.ylim(0,50)\nplt.xlim(0,50)\nplt.title('example linear plots')\nplt.legend(['y=2x-4', 'y=x'])\nplt.grid()\nplt.show()\n\n\n\n\nThe orange line is where y = x\nThe blue line is where y = 2x - 4"
  },
  {
    "objectID": "past-events/past-events.html",
    "href": "past-events/past-events.html",
    "title": "Past events",
    "section": "",
    "text": "Numpy deep dive\n\n\n\n\n\n\n\n\n\n\n\n\nDec 21, 2022\n\n\nPeter O’Connor\n\n\n\n\n\n\n  \n\n\n\n\nChat-GPT: The architecture behind the model\n\n\n\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\nPeter O’Connor\n\n\n\n\n\n\n  \n\n\n\n\nIntro to machine learning\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 1, 2023\n\n\nMike Gallimore\n\n\n\n\n\n\n  \n\n\n\n\nFrom Scratch Model part 1: Getting set up with a free cloud machine learning environment in six easy steps\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 8, 2023\n\n\nMike Gallimore\n\n\n\n\n\n\n  \n\n\n\n\nFrom scratch model part 2: training an image recognition model using fastai\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 8, 2023\n\n\nMike Gallimore\n\n\n\n\n\n\n  \n\n\n\n\nEric’s talk on Quantum ML\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\nEric Drechsler\n\n\n\n\n\n\n  \n\n\n\n\nGeospatial 101\n\n\n\n\n\n\n\n\n\n\n\n\nMar 22, 2023\n\n\nElliot Salisbury\n\n\n\n\n\n\n  \n\n\n\n\nDeveloping Chatbots in an evolving AI landscape\n\n\n\n\n\n\n\n\n\n\n\n\nMay 10, 2023\n\n\nGuillaumen Slevan-Tremblay\n\n\n\n\n\n\n  \n\n\n\n\nAI Alignment - why AI: might or might not kill us all\n\n\n\n\n\n\n\n\n\n\n\n\nMay 24, 2023\n\n\nIlva Ravinska\n\n\n\n\n\n\n  \n\n\n\n\nVersion Control 101\n\n\n\n\n\n\n\n\n\n\n\n\nJun 7, 2023\n\n\nMike Gallimore & Peter O’Connor\n\n\n\n\n\n\n  \n\n\n\n\nEagle Eyes Search\n\n\n\n\n\nComputer vision for drones for SAR\n\n\n\n\n\n\nJun 22, 2023\n\n\nPeter O’Connor\n\n\n\n\n\n\n  \n\n\n\n\nGetting set up with Paperspace Gradient in six easy steps\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nRunning a model on GPU in Jupyter Notebook.\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nVersion Control 101.\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat’s this all about?\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "We are a group of Squamish residents connected over a common interest in machine learning, data science and AI.\nWe aim to grow skills and knowledge, and make connections through a series of talks, group coding events, pair programming and hackathons.\nWe aim to provide a place for people to share knowledge in the domains of data science, machine learning and artificial intelligence. We try to structure our talks to be as participatory as possible - rather than just a lecture on a topic, we encourage input and material from our members, and encourage debate in the hope that this stimulates learning and growth of our members.\nTo get involved, come along on Wednesday evenings to meet the group!\nYou can shoot us an email here: mlsquamish@gmail.com\nWe host our meets at The Common - a community workspace on Cleveland. Check out their website and definitely give them a try if you have a remote job and want an office space.\nYou can get 1/3 off your first 3 months of membership at The Common by obtaining a referral code from us."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Home",
    "section": "",
    "text": "Welcome to our landing page.\n\n\nNext event: Thursday October 5th, 6:30pm at The Common\nHi! It’s our first meet back since summer break. If you’re working in machine learning, data science or AI, or just interested in those fields, then come along to our first social this season. It’s pretty informal, and welcoming to people from all backgrounds and abilities.   Here’s the schedule for the evening:  6:30 - 7:00: 30 mins arrival and setup -get seated, meet people, get a beer, etc.  7:30 - 8:30: Peter O’Connor has a talk prepared. Subject TBA.  8:30 - 8:40: Get another beer and break 10 mins.  8:40 - 9:00: Mike will walk us through a blog on embeddings and collaborative filtering models (AKA Reccomender Systems).  9:00 - end: Social and clean up for remainder of the evening.\nHope to see you there!\n\n\nClick to see past events"
  },
  {
    "objectID": "past-events/site-test2/index.html",
    "href": "past-events/site-test2/index.html",
    "title": "testing python code content",
    "section": "",
    "text": "Testing the site’s ability to display python code.\npython"
  },
  {
    "objectID": "past-events/numpy-peter/numpy-tutorial.html",
    "href": "past-events/numpy-peter/numpy-tutorial.html",
    "title": "ML Squamish",
    "section": "",
    "text": "A low level intro to the use of numerical libraries (mainly Pytorch but also Numpy and Tensorflow) for machine learning.\n\n\n\nGet everyone familiar with the basics of array-manipulation.\nMake sure even those people already familiar learn something new.\nIntroduce pytorch from the bottom-up.\n\n\n\n\nLibraries like Numpy, PyTorch, and Tensorflow use N-dimensional arrays as a basic datatype. They allow you to manipulate arrays much more compactily and faster than if you were to use native python. Behind the scenes, they do all the looping in C - which will typically be around 20-100x faster than doing it in python.\n\nfrom timeit import timeit\nt1=timeit(\"sum(ai*bi for ai, bi in zip(a, b))\", setup=\"import random; N=10000000; a=[random.gauss(0, 1) for _ in range(N)]; b=[random.gauss(0, 1) for _ in range(N)]\", number = 10)\nt2=timeit(\"(a*b).sum()\", setup=\"import numpy as np; N=10000000; a, b = np.random.randn(2, N)\", number = 10)\nprint(f\"With python looping: t={t1:.3f}, with numpy looping: t={t2:.3f}.  Speedup factor: {t1/t2:.0f}x\")\n\nWith python looping: t=9.208, with numpy looping: t=0.352.  Speedup factor: 26x"
  },
  {
    "objectID": "past-events/paperspace-tutorial/index.html",
    "href": "past-events/paperspace-tutorial/index.html",
    "title": "Getting set up with cloud computing on Paperspace Gradient",
    "section": "",
    "text": "Walkthrough on getting set up with paperspace.\nnotebook"
  },
  {
    "objectID": "past-events/paperspace-tutorial/paperspace.html",
    "href": "past-events/paperspace-tutorial/paperspace.html",
    "title": "ML Squamish",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n: \n\n\n\n\nThe following function describes a straight line , where m is the gradient and c is the y intercept:\n\\[\n\\large y = mx + c\n\\]\nWe can show that this equation plots a straight line by experiment: making a set of inputs x, and calculating the corresponding values of y, a function of x:\n\nx = np.linspace(0,49)\nm = 2\nc = -4\nprint(f'm = {m}, c = {c}')\n\nm = 2, c = -4\n\n\n\nx\n\narray([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,\n       39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49.])\n\n\n\ny = m*x+c\ny\n\narray([-4., -2.,  0.,  2.,  4.,  6.,  8., 10., 12., 14., 16., 18., 20.,\n       22., 24., 26., 28., 30., 32., 34., 36., 38., 40., 42., 44., 46.,\n       48., 50., 52., 54., 56., 58., 60., 62., 64., 66., 68., 70., 72.,\n       74., 76., 78., 80., 82., 84., 86., 88., 90., 92., 94.])\n\n\n\nplt.plot(x,y)\nplt.plot(x,x)\nplt.ylim(0,50)\nplt.xlim(0,50)\nplt.title('example linear plots')\nplt.legend(['y=2x-4', 'y=x'])\nplt.grid()\nplt.show()\n\n\n\n\nThe orange line is where y = x\nThe blue line is where y = 2x - 4"
  },
  {
    "objectID": "resources/paperspace-tutorial/index.html",
    "href": "resources/paperspace-tutorial/index.html",
    "title": "Getting set up with cloud computing on Paperspace Gradient",
    "section": "",
    "text": "Walkthrough on getting set up with paperspace.\nPaperspace Setup\nTraining a model"
  },
  {
    "objectID": "resources/resources.html",
    "href": "resources/resources.html",
    "title": "Resources",
    "section": "",
    "text": "Here’s part 1 of the Git tutorial\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\nVersion Control 101.\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "resources/paperspace-tutorial/boats-example.html",
    "href": "resources/paperspace-tutorial/boats-example.html",
    "title": "ML Squamish",
    "section": "",
    "text": "type ? or ?? next to a function then shift + return to execute the cell to get the source code.\nPress shift + tab inside function’s parentheses to get function signature and docstring\nType the name of a module and hit enter to get info about its type and location."
  },
  {
    "objectID": "resources/paperspace-tutorial/boats-example.html#change-your-code-to-reflect-the-categories-youre-using.",
    "href": "resources/paperspace-tutorial/boats-example.html#change-your-code-to-reflect-the-categories-youre-using.",
    "title": "ML Squamish",
    "section": "Change your code to reflect the categories you’re using.",
    "text": "Change your code to reflect the categories you’re using.\n\nboat_types = 'canoe', 'kayak', 'sailboat'\n\n\npath = Path('boats')\n\nDownload images from chosen categories.\nThis cell may take a few minutes to run\n\nif not path.exists():\n    path.mkdir()\n    for boat in boat_types:\n        dest = (path/boat)\n        dest.mkdir(exist_ok=True)\n        results = search_images(boat)\n        download_images(dest, urls=results)\n\n\n!ls {path}\npath\n\ncanoe  kayak  sailboat\n\n\nPath('boats')\n\n\n\nfilenames = get_image_files(path)\nfilenames\n\n(#554) [Path('boats/sailboat/3b873c96-0d1f-4404-9aae-af25d3805177.jpg'),Path('boats/sailboat/6336c57d-8ad9-4318-836c-fba58b5357be.jpg'),Path('boats/sailboat/d2a981d0-0d3e-4b0e-a077-a5cbda1a41b0.JPG'),Path('boats/sailboat/da7dc60e-7c83-4807-9fc1-a0f5061a5080.jpg'),Path('boats/sailboat/168643af-803b-4783-8c6b-a785157c481e.jpeg'),Path('boats/sailboat/f4055206-199c-42a8-bf74-8ed6c4dc7e08.jpg'),Path('boats/sailboat/d5883260-5325-41cb-a645-016051c37819.jpg'),Path('boats/sailboat/4b44e5d8-75e1-413b-a9b9-bd3f19b63df4.jpg'),Path('boats/sailboat/86d8f1b9-b75b-467f-8476-2d91805a150b.jpg'),Path('boats/sailboat/e07b4c1d-a717-4c10-9059-005016798081.jpeg')...]\n\n\n\nfailed = verify_images(filenames)\n\n\nfailed\n\n(#0) []\n\n\n\nfailed.map(Path.unlink)\n\n(#0) []\n\n\n\nfailed\n\n(#0) []"
  },
  {
    "objectID": "resources/paperspace-tutorial/boats-example.html#create-a-way-to-load-datasets-and-dataloaders",
    "href": "resources/paperspace-tutorial/boats-example.html#create-a-way-to-load-datasets-and-dataloaders",
    "title": "ML Squamish",
    "section": "Create a way to load datasets and dataloaders",
    "text": "Create a way to load datasets and dataloaders\n\nboats = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128)\n)\n\n\ndataloaders = boats.dataloaders(path)\n\n\ndataloaders.device\n\ndevice(type='cuda', index=0)\n\n\nIf the device type is ‘cuda’ that means we’ve got the model on the GPU. If device type is ‘cpu’ then now’s a good time to see if there is a free GPU instance available. The data you downloaded earlier won’t be lost since Paperspace has persistent storage.\n\n# Docs for some modules. Uncomment as required. \n# DataLoader?\n# DataLoaders?\n# Datasets?\n# torch.utils.data.Dataset?\n# torch.utils.data.DataLoader?"
  },
  {
    "objectID": "resources/paperspace-tutorial/boats-example.html#training-and-validation-sets",
    "href": "resources/paperspace-tutorial/boats-example.html#training-and-validation-sets",
    "title": "ML Squamish",
    "section": "Training and validation sets",
    "text": "Training and validation sets\nOur data is split into training and validation batches. 20% of the data is in the validation set, and 80% is in the training set.\nDataset: an iterable over tuples containing images with their corresponding category.  DataLoader: a PyTorch iterable returning a batch of datasets. DataLoaders: a fastai iterable which splits dataloaders into training and validation datasets.\n\ndataloaders.train.show_batch()"
  },
  {
    "objectID": "resources/paperspace-tutorial/boats-example.html#train-a-model",
    "href": "resources/paperspace-tutorial/boats-example.html#train-a-model",
    "title": "ML Squamish",
    "section": "Train a model",
    "text": "Train a model\n\nlearn = vision_learner(dataloaders, resnet18, metrics=error_rate)\nlearn.fine_tune(4)\nlearn.recorder.plot_loss()\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      1.512921\n      0.358238\n      0.145455\n      00:13\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.609499\n      0.233965\n      0.100000\n      00:13\n    \n    \n      1\n      0.459157\n      0.267047\n      0.118182\n      00:13\n    \n    \n      2\n      0.373013\n      0.286165\n      0.118182\n      00:13\n    \n    \n      3\n      0.338020\n      0.260390\n      0.109091\n      00:13"
  },
  {
    "objectID": "past-events/model-from-scratch-mike/paperspace-tutorial/index.html",
    "href": "past-events/model-from-scratch-mike/paperspace-tutorial/index.html",
    "title": "Getting set up with cloud computing on Paperspace Gradient",
    "section": "",
    "text": "Walkthrough on getting set up with paperspace.\nPaperspace Setup\nTraining a model"
  },
  {
    "objectID": "past-events/model-from-scratch-mike/paperspace-tutorial/boats-example.html",
    "href": "past-events/model-from-scratch-mike/paperspace-tutorial/boats-example.html",
    "title": "ML Squamish",
    "section": "",
    "text": "type ? or ?? next to a function then shift + return to execute the cell to get the source code.\nPress shift + tab inside function’s parentheses to get function signature and docstring\nType the name of a module and hit enter to get info about its type and location."
  },
  {
    "objectID": "past-events/model-from-scratch-mike/paperspace-tutorial/boats-example.html#change-your-code-to-reflect-the-categories-youre-using.",
    "href": "past-events/model-from-scratch-mike/paperspace-tutorial/boats-example.html#change-your-code-to-reflect-the-categories-youre-using.",
    "title": "ML Squamish",
    "section": "Change your code to reflect the categories you’re using.",
    "text": "Change your code to reflect the categories you’re using.\n\nboat_types = 'canoe', 'kayak', 'sailboat'\n\n\npath = Path('boats')\n\nDownload images from chosen categories.\nThis cell may take a few minutes to run\n\nif not path.exists():\n    path.mkdir()\n    for boat in boat_types:\n        dest = (path/boat)\n        dest.mkdir(exist_ok=True)\n        results = search_images(boat)\n        download_images(dest, urls=results)\n\n\n!ls {path}\npath\n\ncanoe  kayak  sailboat\n\n\nPath('boats')\n\n\n\nfilenames = get_image_files(path)\nfilenames\n\n(#554) [Path('boats/sailboat/3b873c96-0d1f-4404-9aae-af25d3805177.jpg'),Path('boats/sailboat/6336c57d-8ad9-4318-836c-fba58b5357be.jpg'),Path('boats/sailboat/d2a981d0-0d3e-4b0e-a077-a5cbda1a41b0.JPG'),Path('boats/sailboat/da7dc60e-7c83-4807-9fc1-a0f5061a5080.jpg'),Path('boats/sailboat/168643af-803b-4783-8c6b-a785157c481e.jpeg'),Path('boats/sailboat/f4055206-199c-42a8-bf74-8ed6c4dc7e08.jpg'),Path('boats/sailboat/d5883260-5325-41cb-a645-016051c37819.jpg'),Path('boats/sailboat/4b44e5d8-75e1-413b-a9b9-bd3f19b63df4.jpg'),Path('boats/sailboat/86d8f1b9-b75b-467f-8476-2d91805a150b.jpg'),Path('boats/sailboat/e07b4c1d-a717-4c10-9059-005016798081.jpeg')...]\n\n\n\nfailed = verify_images(filenames)\n\n\nfailed\n\n(#0) []\n\n\n\nfailed.map(Path.unlink)\n\n(#0) []\n\n\n\nfailed\n\n(#0) []"
  },
  {
    "objectID": "past-events/model-from-scratch-mike/paperspace-tutorial/boats-example.html#create-a-way-to-load-datasets-and-dataloaders",
    "href": "past-events/model-from-scratch-mike/paperspace-tutorial/boats-example.html#create-a-way-to-load-datasets-and-dataloaders",
    "title": "ML Squamish",
    "section": "Create a way to load datasets and dataloaders",
    "text": "Create a way to load datasets and dataloaders\n\nboats = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128)\n)\n\n\ndataloaders = boats.dataloaders(path)\n\n\ndataloaders.device\n\ndevice(type='cuda', index=0)\n\n\nIf the device type is ‘cuda’ that means we’ve got the model on the GPU. If device type is ‘cpu’ then now’s a good time to see if there is a free GPU instance available. The data you downloaded earlier won’t be lost since Paperspace has persistent storage.\n\n# Docs for some modules. Uncomment as required. \n# DataLoader?\n# DataLoaders?\n# Datasets?\n# torch.utils.data.Dataset?\n# torch.utils.data.DataLoader?"
  },
  {
    "objectID": "past-events/model-from-scratch-mike/paperspace-tutorial/boats-example.html#training-and-validation-sets",
    "href": "past-events/model-from-scratch-mike/paperspace-tutorial/boats-example.html#training-and-validation-sets",
    "title": "ML Squamish",
    "section": "Training and validation sets",
    "text": "Training and validation sets\nOur data is split into training and validation batches. 20% of the data is in the validation set, and 80% is in the training set.\nDataset: an iterable over tuples containing images with their corresponding category.  DataLoader: a PyTorch iterable returning a batch of datasets. DataLoaders: a fastai iterable which splits dataloaders into training and validation datasets.\n\ndataloaders.train.show_batch()"
  },
  {
    "objectID": "past-events/model-from-scratch-mike/paperspace-tutorial/boats-example.html#train-a-model",
    "href": "past-events/model-from-scratch-mike/paperspace-tutorial/boats-example.html#train-a-model",
    "title": "ML Squamish",
    "section": "Train a model",
    "text": "Train a model\n\nlearn = vision_learner(dataloaders, resnet18, metrics=error_rate)\nlearn.fine_tune(4)\nlearn.recorder.plot_loss()\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      1.512921\n      0.358238\n      0.145455\n      00:13\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.609499\n      0.233965\n      0.100000\n      00:13\n    \n    \n      1\n      0.459157\n      0.267047\n      0.118182\n      00:13\n    \n    \n      2\n      0.373013\n      0.286165\n      0.118182\n      00:13\n    \n    \n      3\n      0.338020\n      0.260390\n      0.109091\n      00:13"
  },
  {
    "objectID": "past-events/model-from-scratch-mike/resources.html",
    "href": "past-events/model-from-scratch-mike/resources.html",
    "title": "Resources",
    "section": "",
    "text": "Some resources for you:\n\n\n\n\n\n\n\n\n  \n\n\n\n\nGetting set up with Paperspace Gradient in six easy steps\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nGetting set up with cloud computing on Paperspace Gradient\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 8, 2023\n\n\nMike\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRunning a model on GPU in Jupyter Notebook.\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "past-events/boats-example.html",
    "href": "past-events/boats-example.html",
    "title": "ML Squamish",
    "section": "",
    "text": "type ? or ?? next to a function then shift + return to execute the cell to get the source code.\nPress shift + tab inside function’s parentheses to get function signature and docstring\nType the name of a module and hit enter to get info about its type and location."
  },
  {
    "objectID": "past-events/boats-example.html#change-your-code-to-reflect-the-categories-youre-using.",
    "href": "past-events/boats-example.html#change-your-code-to-reflect-the-categories-youre-using.",
    "title": "ML Squamish",
    "section": "Change your code to reflect the categories you’re using.",
    "text": "Change your code to reflect the categories you’re using.\n\nboat_types = 'canoe', 'kayak', 'sailboat'\n\n\npath = Path('boats')\n\nDownload images from chosen categories.\nThis cell may take a few minutes to run\n\nif not path.exists():\n    path.mkdir()\n    for boat in boat_types:\n        dest = (path/boat)\n        dest.mkdir(exist_ok=True)\n        results = search_images(boat)\n        download_images(dest, urls=results)\n\n\n!ls {path}\npath\n\ncanoe  kayak  sailboat\n\n\nPath('boats')\n\n\n\nfilenames = get_image_files(path)\nfilenames\n\n(#554) [Path('boats/sailboat/3b873c96-0d1f-4404-9aae-af25d3805177.jpg'),Path('boats/sailboat/6336c57d-8ad9-4318-836c-fba58b5357be.jpg'),Path('boats/sailboat/d2a981d0-0d3e-4b0e-a077-a5cbda1a41b0.JPG'),Path('boats/sailboat/da7dc60e-7c83-4807-9fc1-a0f5061a5080.jpg'),Path('boats/sailboat/168643af-803b-4783-8c6b-a785157c481e.jpeg'),Path('boats/sailboat/f4055206-199c-42a8-bf74-8ed6c4dc7e08.jpg'),Path('boats/sailboat/d5883260-5325-41cb-a645-016051c37819.jpg'),Path('boats/sailboat/4b44e5d8-75e1-413b-a9b9-bd3f19b63df4.jpg'),Path('boats/sailboat/86d8f1b9-b75b-467f-8476-2d91805a150b.jpg'),Path('boats/sailboat/e07b4c1d-a717-4c10-9059-005016798081.jpeg')...]\n\n\n\nfailed = verify_images(filenames)\n\n\nfailed\n\n(#0) []\n\n\n\nfailed.map(Path.unlink)\n\n(#0) []\n\n\n\nfailed\n\n(#0) []"
  },
  {
    "objectID": "past-events/boats-example.html#create-a-way-to-load-datasets-and-dataloaders",
    "href": "past-events/boats-example.html#create-a-way-to-load-datasets-and-dataloaders",
    "title": "ML Squamish",
    "section": "Create a way to load datasets and dataloaders",
    "text": "Create a way to load datasets and dataloaders\n\nboats = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128)\n)\n\n\ndataloaders = boats.dataloaders(path)\n\n\ndataloaders.device\n\ndevice(type='cuda', index=0)\n\n\nIf the device type is ‘cuda’ that means we’ve got the model on the GPU. If device type is ‘cpu’ then now’s a good time to see if there is a free GPU instance available. The data you downloaded earlier won’t be lost since Paperspace has persistent storage.\n\n# Docs for some modules. Uncomment as required. \n# DataLoader?\n# DataLoaders?\n# Datasets?\n# torch.utils.data.Dataset?\n# torch.utils.data.DataLoader?"
  },
  {
    "objectID": "past-events/boats-example.html#training-and-validation-sets",
    "href": "past-events/boats-example.html#training-and-validation-sets",
    "title": "ML Squamish",
    "section": "Training and validation sets",
    "text": "Training and validation sets\nOur data is split into training and validation batches. 20% of the data is in the validation set, and 80% is in the training set.\nDataset: an iterable over tuples containing images with their corresponding category.  DataLoader: a PyTorch iterable returning a batch of datasets. DataLoaders: a fastai iterable which splits dataloaders into training and validation datasets.\n\ndataloaders.train.show_batch()"
  },
  {
    "objectID": "past-events/boats-example.html#train-a-model",
    "href": "past-events/boats-example.html#train-a-model",
    "title": "ML Squamish",
    "section": "Train a model",
    "text": "Train a model\n\nlearn = vision_learner(dataloaders, resnet18, metrics=error_rate)\nlearn.fine_tune(4)\nlearn.recorder.plot_loss()\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      1.512921\n      0.358238\n      0.145455\n      00:13\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.609499\n      0.233965\n      0.100000\n      00:13\n    \n    \n      1\n      0.459157\n      0.267047\n      0.118182\n      00:13\n    \n    \n      2\n      0.373013\n      0.286165\n      0.118182\n      00:13\n    \n    \n      3\n      0.338020\n      0.260390\n      0.109091\n      00:13"
  },
  {
    "objectID": "past-events/from-scratch-model-mike/index.html",
    "href": "past-events/from-scratch-model-mike/index.html",
    "title": "From scratch model part 2: training an image recognition model using fastai",
    "section": "",
    "text": "In this presentation Mike walked us through how to train an image classifier using the fastai library. This was a group coding session from no-code to a working model.\nnotebook"
  },
  {
    "objectID": "past-events/from-scratch-model-mike/boats-example.html",
    "href": "past-events/from-scratch-model-mike/boats-example.html",
    "title": "ML Squamish",
    "section": "",
    "text": "type ? or ?? next to a function then shift + return to execute the cell to get the source code.\nPress shift + tab inside function’s parentheses to get function signature and docstring\nType the name of a module and hit enter to get info about its type and location."
  },
  {
    "objectID": "past-events/from-scratch-model-mike/boats-example.html#change-your-code-to-reflect-the-categories-youre-using.",
    "href": "past-events/from-scratch-model-mike/boats-example.html#change-your-code-to-reflect-the-categories-youre-using.",
    "title": "ML Squamish",
    "section": "Change your code to reflect the categories you’re using.",
    "text": "Change your code to reflect the categories you’re using.\n\nboat_types = 'canoe', 'kayak', 'sailboat'\n\n\npath = Path('boats')\n\nDownload images from chosen categories.\nThis cell may take a few minutes to run\n\nif not path.exists():\n    path.mkdir()\n    for boat in boat_types:\n        dest = (path/boat)\n        dest.mkdir(exist_ok=True)\n        results = search_images(boat)\n        download_images(dest, urls=results)\n\n\n!ls {path}\npath\n\ncanoe  kayak  sailboat\n\n\nPath('boats')\n\n\n\nfilenames = get_image_files(path)\nfilenames\n\n(#554) [Path('boats/sailboat/3b873c96-0d1f-4404-9aae-af25d3805177.jpg'),Path('boats/sailboat/6336c57d-8ad9-4318-836c-fba58b5357be.jpg'),Path('boats/sailboat/d2a981d0-0d3e-4b0e-a077-a5cbda1a41b0.JPG'),Path('boats/sailboat/da7dc60e-7c83-4807-9fc1-a0f5061a5080.jpg'),Path('boats/sailboat/168643af-803b-4783-8c6b-a785157c481e.jpeg'),Path('boats/sailboat/f4055206-199c-42a8-bf74-8ed6c4dc7e08.jpg'),Path('boats/sailboat/d5883260-5325-41cb-a645-016051c37819.jpg'),Path('boats/sailboat/4b44e5d8-75e1-413b-a9b9-bd3f19b63df4.jpg'),Path('boats/sailboat/86d8f1b9-b75b-467f-8476-2d91805a150b.jpg'),Path('boats/sailboat/e07b4c1d-a717-4c10-9059-005016798081.jpeg')...]\n\n\n\nfailed = verify_images(filenames)\n\n\nfailed\n\n(#0) []\n\n\n\nfailed.map(Path.unlink)\n\n(#0) []\n\n\n\nfailed\n\n(#0) []"
  },
  {
    "objectID": "past-events/from-scratch-model-mike/boats-example.html#create-a-way-to-load-datasets-and-dataloaders",
    "href": "past-events/from-scratch-model-mike/boats-example.html#create-a-way-to-load-datasets-and-dataloaders",
    "title": "ML Squamish",
    "section": "Create a way to load datasets and dataloaders",
    "text": "Create a way to load datasets and dataloaders\n\nboats = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128)\n)\n\n\ndataloaders = boats.dataloaders(path)\n\n\ndataloaders.device\n\ndevice(type='cuda', index=0)\n\n\nIf the device type is ‘cuda’ that means we’ve got the model on the GPU. If device type is ‘cpu’ then now’s a good time to see if there is a free GPU instance available. The data you downloaded earlier won’t be lost since Paperspace has persistent storage.\n\n# Docs for some modules. Uncomment as required. \n# DataLoader?\n# DataLoaders?\n# Datasets?\n# torch.utils.data.Dataset?\n# torch.utils.data.DataLoader?"
  },
  {
    "objectID": "past-events/from-scratch-model-mike/boats-example.html#training-and-validation-sets",
    "href": "past-events/from-scratch-model-mike/boats-example.html#training-and-validation-sets",
    "title": "ML Squamish",
    "section": "Training and validation sets",
    "text": "Training and validation sets\nOur data is split into training and validation batches. 20% of the data is in the validation set, and 80% is in the training set.\nDataset: an iterable over tuples containing images with their corresponding category.  DataLoader: a PyTorch iterable returning a batch of datasets. DataLoaders: a fastai iterable which splits dataloaders into training and validation datasets.\n\ndataloaders.train.show_batch()"
  },
  {
    "objectID": "past-events/from-scratch-model-mike/boats-example.html#train-a-model",
    "href": "past-events/from-scratch-model-mike/boats-example.html#train-a-model",
    "title": "ML Squamish",
    "section": "Train a model",
    "text": "Train a model\n\nlearn = vision_learner(dataloaders, resnet18, metrics=error_rate)\nlearn.fine_tune(4)\nlearn.recorder.plot_loss()\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      1.512921\n      0.358238\n      0.145455\n      00:13\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.609499\n      0.233965\n      0.100000\n      00:13\n    \n    \n      1\n      0.459157\n      0.267047\n      0.118182\n      00:13\n    \n    \n      2\n      0.373013\n      0.286165\n      0.118182\n      00:13\n    \n    \n      3\n      0.338020\n      0.260390\n      0.109091\n      00:13"
  },
  {
    "objectID": "past-events/paperspace-setup-mike/index.html",
    "href": "past-events/paperspace-setup-mike/index.html",
    "title": "From Scratch Model part 1: Getting set up with a free cloud machine learning environment in six easy steps",
    "section": "",
    "text": "This is part 1 of Mike’s model from scratch presentation. This was a group coding session from no-code to a working model. This notebook walks through how to get set up with a free cloud computer capable of running machine learning code on a GPU.\nnotebook"
  },
  {
    "objectID": "past-events/eric-quantum-ml/index.html",
    "href": "past-events/eric-quantum-ml/index.html",
    "title": "Eric’s talk on Quantum ML",
    "section": "",
    "text": "This was a fascinating talk on quantum physics, quantum computing and some applications of machine learning within all of this. Check out the slideshow here:\npdf slides"
  },
  {
    "objectID": "past-events/elliot-geospatial/index.html",
    "href": "past-events/elliot-geospatial/index.html",
    "title": "Geospatial 101",
    "section": "",
    "text": "Elliot gave an excellent 101 class on processing geospatial data for data scientists who haven’t worked on that kind of data before.\nHe outlined some of the things you should be aware of, so if and when you deal with that kind of data yourself, you know how to diagnose the problems and search for what you need to solve the issues you’re facing.\nThanks for putting this together Elliot!\nslides\nCheck out the notebook from this talk!"
  },
  {
    "objectID": "resources/notebook.html",
    "href": "resources/notebook.html",
    "title": "ML Squamish",
    "section": "",
    "text": "logo-mls.png"
  },
  {
    "objectID": "resources/notebook.html#get-online",
    "href": "resources/notebook.html#get-online",
    "title": "ML Squamish",
    "section": "Get online",
    "text": "Get online\nusername:\npassword:"
  },
  {
    "objectID": "resources/notebook.html#install-git",
    "href": "resources/notebook.html#install-git",
    "title": "ML Squamish",
    "section": "install git",
    "text": "install git\n\nLinux:\nhead to terminal and enter sudo dnf install git-all\n\n\nMac OS:\nopen Terminal and enter $ git --version then follow prompts to install.\nIf you don’t have XCode tools installed, you might need to install homebrew, then once that’s setup type brew install git\n\n\nWindows:\ndownload and install from https://git-scm.com/download/win\nHaving trouble?\nPoke around here https://git-scm.com/book/en/v2/Getting-Started-Installing-Git\nGoogle or check stack overflow\nAsk for help if someone is free!"
  },
  {
    "objectID": "resources/notebook.html#making-a-different-branch",
    "href": "resources/notebook.html#making-a-different-branch",
    "title": "ML Squamish",
    "section": "Making a different branch",
    "text": "Making a different branch\nWe’re currently on the master branch. We could make some changes on a different branch and the original branch will remain unchanged until we merge the brances back together later. Let’s try this! \ngit branch ellys-edit\ngit checkout ellys-edit\n\ngit branch \nThe green text indicates the branch we’re currently on\nNow we’re on the new branch, let’s make some changes.\nIn this scenario, Elly has been given the task of arranging food for the trip. She creates a new file called food.txt and populates it with important food supplies.\nWhile she’s at it, she realizes that the forecast is for cloud and rain, so she removes sunscreen and sunglasses from the original packing list.\nFinally, she renames the README file to gear.txt \nHere’s what the changes look like in the terminal \nTo commit these changes to the master branch, we can run git add . then commit the changes."
  },
  {
    "objectID": "resources/notebook.html#switching-between-branches",
    "href": "resources/notebook.html#switching-between-branches",
    "title": "ML Squamish",
    "section": "Switching between branches",
    "text": "Switching between branches\nBy typing git checkout master and git checkout ellys-branch we can switch between branches. This changes the contents of the directory - have a play with it with the directory open."
  },
  {
    "objectID": "resources/notebook.html#merging-two-branches",
    "href": "resources/notebook.html#merging-two-branches",
    "title": "ML Squamish",
    "section": "Merging two branches",
    "text": "Merging two branches\nTo merge the changes from another branch, into the one we’re currently on, we can use git merge ellys-edit from the master branch."
  },
  {
    "objectID": "resources/notebook.html#merge-conflict",
    "href": "resources/notebook.html#merge-conflict",
    "title": "ML Squamish",
    "section": "merge conflict",
    "text": "merge conflict\nMaking edits like this works most of the time, but sometimes we have a conflict, for example when someone edits the same line as code as you - and it isn’t obvious how to merge these edits. In this case we’ll see an error message and we’ll be asked which edit to keep.\nLet’s check this out by supposing that I want to save weight by replacing the beer with an empty water bottle, and Elly wants to take it to the next level by ditching the burgers, and adding more beer…\nI’ve changed to the respective branches and made the edits to this, and committed the changes on each branch.\nLook at the git log on each branch to see what was done. \nand on ellys-edit:"
  },
  {
    "objectID": "resources/notebook.html#lets-try-a-git-merge",
    "href": "resources/notebook.html#lets-try-a-git-merge",
    "title": "ML Squamish",
    "section": "Let’s try a git merge:",
    "text": "Let’s try a git merge:\n\nGit status gives us more info on the merge conflict - both the branches being merged attempt to modify the same file."
  },
  {
    "objectID": "index.html#git-github-and-github-co-pilot-tutorial-evening",
    "href": "index.html#git-github-and-github-co-pilot-tutorial-evening",
    "title": "Home",
    "section": "Git, GitHub and GitHub Co-Pilot tutorial evening",
    "text": "Git, GitHub and GitHub Co-Pilot tutorial evening\nCommunity coding event. This Wednesday 7th June at The Common, Cleveland Ave.\nCome along at 6:30 if you already have Git installed, or 6pm if you don’t and would like some help getting set up.\nBring your laptops!\nPast Events\nGit walkthrough"
  },
  {
    "objectID": "resources/git-walkthrough.html",
    "href": "resources/git-walkthrough.html",
    "title": "ML Squamish",
    "section": "",
    "text": "Community coding event. This Wednesday 7th June to The Common, Cleveland Ave.\nCome along at 6:30 if you already have Git installed, or 6pm if you don’t and would like some help getting set up."
  },
  {
    "objectID": "resources/git-walkthrough.html#get-online",
    "href": "resources/git-walkthrough.html#get-online",
    "title": "ML Squamish",
    "section": "Get online",
    "text": "Get online\nusername:\npassword:"
  },
  {
    "objectID": "resources/git-walkthrough.html#install-git",
    "href": "resources/git-walkthrough.html#install-git",
    "title": "ML Squamish",
    "section": "install git",
    "text": "install git\n\nLinux:\nhead to terminal and enter sudo dnf install git-all\n\n\nMac OS:\nopen Terminal and enter $ git --version then follow prompts to install.\nIf you don’t have XCode tools installed, you might need to install homebrew, then once that’s setup type brew install git\n\n\nWindows:\ndownload and install from https://git-scm.com/download/win\nHaving trouble?\nPoke around here https://git-scm.com/book/en/v2/Getting-Started-Installing-Git\nGoogle or check stack overflow\nAsk for help if someone is free!"
  },
  {
    "objectID": "resources/git-walkthrough.html#making-a-different-branch",
    "href": "resources/git-walkthrough.html#making-a-different-branch",
    "title": "ML Squamish",
    "section": "Making a different branch",
    "text": "Making a different branch\nWe’re currently on the master branch. We could make some changes on a different branch and the original branch will remain unchanged until we merge the brances back together later. Let’s try this! \ngit branch ellys-edit\ngit checkout ellys-edit\n\ngit branch\n\nThe green text indicates the branch we’re currently on\nNow we’re on the new branch, let’s make some changes.\nIn this scenario, Elly has been given the task of arranging food for the trip. She creates a new file called food.txt and populates it with important food supplies.\nWhile she’s at it, she realizes that the forecast is for cloud and rain, so she removes sunscreen and sunglasses from the original packing list.\nFinally, she renames the README file to gear.txt \nHere’s what the changes look like in the terminal \nTo commit these changes to the master branch, we can run git add . then commit the changes."
  },
  {
    "objectID": "resources/git-walkthrough.html#switching-between-branches",
    "href": "resources/git-walkthrough.html#switching-between-branches",
    "title": "ML Squamish",
    "section": "Switching between branches",
    "text": "Switching between branches\nBy typing git checkout master and git checkout ellys-branch we can switch between branches. This changes the contents of the directory - have a play with it with the directory open."
  },
  {
    "objectID": "resources/git-walkthrough.html#merging-two-branches",
    "href": "resources/git-walkthrough.html#merging-two-branches",
    "title": "ML Squamish",
    "section": "Merging two branches",
    "text": "Merging two branches\nTo merge the changes from another branch, into the one we’re currently on, we can use git merge ellys-edit from the master branch."
  },
  {
    "objectID": "resources/git-walkthrough.html#merge-conflict",
    "href": "resources/git-walkthrough.html#merge-conflict",
    "title": "ML Squamish",
    "section": "merge conflict",
    "text": "merge conflict\nMaking edits like this works most of the time, but sometimes we have a conflict, for example when someone edits the same line as code as you - and it isn’t obvious how to merge these edits. In this case we’ll see an error message and we’ll be asked which edit to keep.\nLet’s check this out by supposing that I want to save weight by replacing the beer with an empty water bottle, and Elly wants to take it to the next level by ditching the burgers, and adding more beer…\nI’ve changed to the respective branches and made the edits to this, and committed the changes on each branch.\nLook at the git log on each branch to see what was done. \nand on ellys-edit:"
  },
  {
    "objectID": "resources/git-walkthrough.html#lets-try-a-git-merge",
    "href": "resources/git-walkthrough.html#lets-try-a-git-merge",
    "title": "ML Squamish",
    "section": "Let’s try a git merge:",
    "text": "Let’s try a git merge:\n\nGit status gives us more info on the merge conflict - both the branches being merged attempt to modify the same file."
  },
  {
    "objectID": "resources/git-walkthrough.html#git-revert",
    "href": "resources/git-walkthrough.html#git-revert",
    "title": "ML Squamish",
    "section": "git revert",
    "text": "git revert\n\nmakes a new commit which is the inverse operation of an existing commit.\nIt allows you to undo the effect of a commit, but still keeps the data which broke your code in case you need to go back.\nthis is also useful to avoid undoing history which other people may have branched off of.\nIf applying the inverse operation of a commit creates merge conflicts, the revert method will fail.\n\nto use git revert, you can either use\ngit revert head\nto rewind by 1 commit.\nor\ngit revert # where the # is the commit hash.\ngit log"
  },
  {
    "objectID": "resources/git-walkthrough.html#interactive-rebase",
    "href": "resources/git-walkthrough.html#interactive-rebase",
    "title": "ML Squamish",
    "section": "interactive rebase",
    "text": "interactive rebase\nSometimes a git-revert isn’t what you need: I once had an issue when trying to push very large files to GitHub. I was a few commits ahead before I decided to sync my project with the company’s github repo, at which point I found that some files exceeded the remote server’s maximum filesize. I used git revert to selectively remove these large files, adding them to a .gitignore as I went.\ninteractive rebase allows you to cycle through multiple commits, picking and choosing which parts of which commits are applied:\n\nTo see the hashes of the commits:\n\ngit log --all --decorate --oneline\n\nand find the commit hash of the last good commit hash before mistake was made.\nthen do an interactive rebase from that point on: let’s say we’re wanting to edit the July 4th commit:\ngit rebase -i 6fae677\na prompt will pop up asking which commits you want to edit and which ones you want to keep unchanged.\nNote on vim: If this opens up in vim, you’ll need to be in Insert mode by pressing esc I, then once you finish editing using esc : wq then hit return.\nAt first all of the commits will say pick in front of them. Change this to edit for the ones you want to modify.\nSave the file first then follow the prompts to cycle through the commits one by one.\nFrom here you’ll need to create a series of commits using\ngit status\nthen edit, add, remove any files which you need in that commit\nAlso resolve any merge conflicts as you go through\nOnce everything is correct for that commit, use\ngit rebase --continue\nto move on to the next commit.\nOnce you’ve cycled through to the last commit, the git rebase is finished."
  },
  {
    "objectID": "resources/git-walkthrough.html#cloning-and-pull-requests",
    "href": "resources/git-walkthrough.html#cloning-and-pull-requests",
    "title": "ML Squamish",
    "section": "cloning and pull requests",
    "text": "cloning and pull requests\nUsing Git and GitHub we can easily copy (pull) an enitre code repository to our local machine, make an edit, then create a request for our edit to be merged back into the original codebase. This is called a Pull Request."
  },
  {
    "objectID": "resources/git-walkthrough.html#ssh-keys",
    "href": "resources/git-walkthrough.html#ssh-keys",
    "title": "ML Squamish",
    "section": "SSH Keys",
    "text": "SSH Keys\nOne of the things you’ll encounter getting your computer talking to GitHub, is setting up an SSH key. This can be quite fiddly, and we don’t have time to go into it in this tutorial - but if you encounter this then here’s a guide on setting up an SSH key on the GitHub website: https://docs.github.com/en/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account"
  },
  {
    "objectID": "resources/git-walkthrough.html#cloning-an-existing-project-on-github",
    "href": "resources/git-walkthrough.html#cloning-an-existing-project-on-github",
    "title": "ML Squamish",
    "section": "Cloning an existing project on GitHub",
    "text": "Cloning an existing project on GitHub\nOnce you’ve got SSH keys setup and working, this is as easy as typing\ngit clone followed by the address of the repo on GitHub\n\nAny changes you make will be local changes, until you commit and push the changes. Pushing the changes will attempt to push back to the repository which was cloned - so if you want to keep your own version of the project separate, you’ll want to fork the repository before cloning it."
  },
  {
    "objectID": "resources/git-walkthrough.html#git-diff",
    "href": "resources/git-walkthrough.html#git-diff",
    "title": "ML Squamish",
    "section": "Git diff",
    "text": "Git diff\ngit diff shows us the difference between the commits, and where the conflict exists. !\n\nWe have a couple of ways to deal with this - we can abort the merge using git merge --abort and use a new command such as git merge --strategy-option ours\nOr we can edit the conflicting file partway through the merge. To do this, head to the file in conflict, and remove all the <<<<<<< HEAD, ======= and >>>>>>> ellys-edit sections, then leave the file as you’d like it in the final merged version.\n\nAt this point I’ve gone ahead and opened up food.txt in a text editor, and left it how I’d like the final version to be. Let’s see how things look in the terminal.\n\nGreat! We’ve installed Git, made a project, edited the project on different branches, done a git merge, and learnt to resolve merge conflicts.\nWhat if we made one or more commits, and later realize that the commit broke a section of code? This is where git revert comes to the rescue."
  },
  {
    "objectID": "index.html#computer-vision-for-drones-for-sar",
    "href": "index.html#computer-vision-for-drones-for-sar",
    "title": "Home",
    "section": "Computer vision for drones for SAR",
    "text": "Computer vision for drones for SAR\nAt first glance - drones seem like the perfect tool for Search and Rescue (SAR) - they can fly over impassable terrain, see body heat, and survey large swaths of land in minutes. But ask any operator what it is like using a drone for SAR, they’ll tell you it is not easy. Many compare the task to finding the proverbial needle in a haystack.\nOn Thursday June 22, 6:30pm at The Common, we’ll dive into the problem and look inside one tool - Eagle Eyes (from a Squamish-based startup), that aims to find that needle.\nIn this deep-dive, we’ll go over the problem faced by SAR drone operators, and how to characterise it through the eyes of computer-vision / machine learning, and our approach to solving it so far. In a one-hour crash course, we’ll learn about precision, recall, false-positives, false-negatives, and the science, and art, of anomaly detection.\nFinally, we’ll open the floor for discussion. Feedback and ideas are most welcome! So whether you’re interested in SAR, machine learning, drones, or new technologies in general, come to learn and contribute to an exciting discussion."
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html",
    "href": "past-events/git-walkthrough/git-walkthrough.html",
    "title": "ML Squamish",
    "section": "",
    "text": "Community coding event. This Wednesday 7th June to The Common, Cleveland Ave.\nCome along at 6:30 if you already have Git installed, or 6pm if you don’t and would like some help getting set up."
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#get-online",
    "href": "past-events/git-walkthrough/git-walkthrough.html#get-online",
    "title": "ML Squamish",
    "section": "Get online",
    "text": "Get online\nusername:\npassword:"
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#install-git",
    "href": "past-events/git-walkthrough/git-walkthrough.html#install-git",
    "title": "ML Squamish",
    "section": "install git",
    "text": "install git\n\nLinux:\nhead to terminal and enter sudo dnf install git-all\n\n\nMac OS:\nopen Terminal and enter $ git --version then follow prompts to install.\nIf you don’t have XCode tools installed, you might need to install homebrew, then once that’s setup type brew install git\n\n\nWindows:\ndownload and install from https://git-scm.com/download/win\nHaving trouble?\nPoke around here https://git-scm.com/book/en/v2/Getting-Started-Installing-Git\nGoogle or check stack overflow\nAsk for help if someone is free!"
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#making-a-different-branch",
    "href": "past-events/git-walkthrough/git-walkthrough.html#making-a-different-branch",
    "title": "ML Squamish",
    "section": "Making a different branch",
    "text": "Making a different branch\nWe’re currently on the master branch. We could make some changes on a different branch and the original branch will remain unchanged until we merge the brances back together later. Let’s try this! \ngit branch ellys-edit\ngit checkout ellys-edit\n\ngit branch\n\nThe green text indicates the branch we’re currently on\nNow we’re on the new branch, let’s make some changes.\nIn this scenario, Elly has been given the task of arranging food for the trip. She creates a new file called food.txt and populates it with important food supplies.\nWhile she’s at it, she realizes that the forecast is for cloud and rain, so she removes sunscreen and sunglasses from the original packing list.\nFinally, she renames the README file to gear.txt \nHere’s what the changes look like in the terminal \nTo commit these changes to the master branch, we can run git add . then commit the changes."
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#switching-between-branches",
    "href": "past-events/git-walkthrough/git-walkthrough.html#switching-between-branches",
    "title": "ML Squamish",
    "section": "Switching between branches",
    "text": "Switching between branches\nBy typing git checkout master and git checkout ellys-branch we can switch between branches. This changes the contents of the directory - have a play with it with the directory open."
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#merging-two-branches",
    "href": "past-events/git-walkthrough/git-walkthrough.html#merging-two-branches",
    "title": "ML Squamish",
    "section": "Merging two branches",
    "text": "Merging two branches\nTo merge the changes from another branch, into the one we’re currently on, we can use git merge ellys-edit from the master branch."
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#merge-conflict",
    "href": "past-events/git-walkthrough/git-walkthrough.html#merge-conflict",
    "title": "ML Squamish",
    "section": "merge conflict",
    "text": "merge conflict\nMaking edits like this works most of the time, but sometimes we have a conflict, for example when someone edits the same line as code as you - and it isn’t obvious how to merge these edits. In this case we’ll see an error message and we’ll be asked which edit to keep.\nLet’s check this out by supposing that I want to save weight by replacing the beer with an empty water bottle, and Elly wants to take it to the next level by ditching the burgers, and adding more beer…\nI’ve changed to the respective branches and made the edits to this, and committed the changes on each branch.\nLook at the git log on each branch to see what was done. \nand on ellys-edit:"
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#lets-try-a-git-merge",
    "href": "past-events/git-walkthrough/git-walkthrough.html#lets-try-a-git-merge",
    "title": "ML Squamish",
    "section": "Let’s try a git merge:",
    "text": "Let’s try a git merge:\n\nGit status gives us more info on the merge conflict - both the branches being merged attempt to modify the same file."
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#git-diff",
    "href": "past-events/git-walkthrough/git-walkthrough.html#git-diff",
    "title": "ML Squamish",
    "section": "Git diff",
    "text": "Git diff\ngit diff shows us the difference between the commits, and where the conflict exists. !\n\nWe have a couple of ways to deal with this - we can abort the merge using git merge --abort and use a new command such as git merge --strategy-option ours\nOr we can edit the conflicting file partway through the merge. To do this, head to the file in conflict, and remove all the <<<<<<< HEAD, ======= and >>>>>>> ellys-edit sections, then leave the file as you’d like it in the final merged version.\n\nAt this point I’ve gone ahead and opened up food.txt in a text editor, and left it how I’d like the final version to be. Let’s see how things look in the terminal.\n\nGreat! We’ve installed Git, made a project, edited the project on different branches, done a git merge, and learnt to resolve merge conflicts.\nWhat if we made one or more commits, and later realize that the commit broke a section of code? This is where git revert comes to the rescue."
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#git-revert",
    "href": "past-events/git-walkthrough/git-walkthrough.html#git-revert",
    "title": "ML Squamish",
    "section": "git revert",
    "text": "git revert\n\nmakes a new commit which is the inverse operation of an existing commit.\nIt allows you to undo the effect of a commit, but still keeps the data which broke your code in case you need to go back.\nthis is also useful to avoid undoing history which other people may have branched off of.\nIf applying the inverse operation of a commit creates merge conflicts, the revert method will fail.\n\nto use git revert, you can either use\ngit revert head\nto rewind by 1 commit.\nor\ngit revert # where the # is the commit hash.\ngit log"
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#interactive-rebase",
    "href": "past-events/git-walkthrough/git-walkthrough.html#interactive-rebase",
    "title": "ML Squamish",
    "section": "interactive rebase",
    "text": "interactive rebase\nSometimes a git-revert isn’t what you need: I once had an issue when trying to push very large files to GitHub. I was a few commits ahead before I decided to sync my project with the company’s github repo, at which point I found that some files exceeded the remote server’s maximum filesize. I used git revert to selectively remove these large files, adding them to a .gitignore as I went.\ninteractive rebase allows you to cycle through multiple commits, picking and choosing which parts of which commits are applied:\n\nTo see the hashes of the commits:\n\ngit log --all --decorate --oneline\n\nand find the commit hash of the last good commit hash before mistake was made.\nthen do an interactive rebase from that point on: let’s say we’re wanting to edit the July 4th commit:\ngit rebase -i 6fae677\na prompt will pop up asking which commits you want to edit and which ones you want to keep unchanged.\nNote on vim: If this opens up in vim, you’ll need to be in Insert mode by pressing esc I, then once you finish editing using esc : wq then hit return.\nAt first all of the commits will say pick in front of them. Change this to edit for the ones you want to modify.\nSave the file first then follow the prompts to cycle through the commits one by one.\nFrom here you’ll need to create a series of commits using\ngit status\nthen edit, add, remove any files which you need in that commit\nAlso resolve any merge conflicts as you go through\nOnce everything is correct for that commit, use\ngit rebase --continue\nto move on to the next commit.\nOnce you’ve cycled through to the last commit, the git rebase is finished."
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#cloning-and-pull-requests",
    "href": "past-events/git-walkthrough/git-walkthrough.html#cloning-and-pull-requests",
    "title": "ML Squamish",
    "section": "cloning and pull requests",
    "text": "cloning and pull requests\nUsing Git and GitHub we can easily copy (pull) an enitre code repository to our local machine, make an edit, then create a request for our edit to be merged back into the original codebase. This is called a Pull Request."
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#ssh-keys",
    "href": "past-events/git-walkthrough/git-walkthrough.html#ssh-keys",
    "title": "ML Squamish",
    "section": "SSH Keys",
    "text": "SSH Keys\nOne of the things you’ll encounter getting your computer talking to GitHub, is setting up an SSH key. This can be quite fiddly, and we don’t have time to go into it in this tutorial - but if you encounter this then here’s a guide on setting up an SSH key on the GitHub website: https://docs.github.com/en/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account"
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#cloning-an-existing-project-on-github",
    "href": "past-events/git-walkthrough/git-walkthrough.html#cloning-an-existing-project-on-github",
    "title": "ML Squamish",
    "section": "Cloning an existing project on GitHub",
    "text": "Cloning an existing project on GitHub\nOnce you’ve got SSH keys setup and working, this is as easy as typing\ngit clone followed by the address of the repo on GitHub\n\nAny changes you make will be local changes, until you commit and push the changes. Pushing the changes will attempt to push back to the repository which was cloned - so if you want to keep your own version of the project separate, you’ll want to fork the repository before cloning it."
  },
  {
    "objectID": "past-events/git-walkthrough/index.html",
    "href": "past-events/git-walkthrough/index.html",
    "title": "Version Control 101",
    "section": "",
    "text": "In this double feature, Mike walked us through how to get set up using Git, then Peter showed us Github Co-pilot, an AI based code completion tool which runs in your editor. This was a group coding session with input from other members of the community.\ngit intro\npeter’s co-pilot presentation"
  },
  {
    "objectID": "past-events/intro-to-ml-mike/index.html",
    "href": "past-events/intro-to-ml-mike/index.html",
    "title": "Intro to machine learning",
    "section": "",
    "text": "This evening was an overview of machine learning for the benefit of newcomers, or people working in related fields.\nClick here to see the slideshow which accompanied the talk"
  },
  {
    "objectID": "past-events/alignment/index.html",
    "href": "past-events/alignment/index.html",
    "title": "AI Alignment - why AI: might or might not kill us all",
    "section": "",
    "text": "Ilva gave a great introduction to the subject of AI alignment and some resources for further reading, providing an opportunity for our community to get together and share knowledge, speculate, and debate this topic."
  },
  {
    "objectID": "past-events/alignment/index.html#big-picture-recommendation",
    "href": "past-events/alignment/index.html#big-picture-recommendation",
    "title": "AI Alignment - why AI: might or might not kill us all",
    "section": "Big Picture Recommendation:",
    "text": "Big Picture Recommendation:\nCold Takes blog - this is the best source for an accessible introduction to the worldview that informs Open Philanthropy’s long-term future grantmaking."
  },
  {
    "objectID": "past-events/alignment/index.html#ai-timelines",
    "href": "past-events/alignment/index.html#ai-timelines",
    "title": "AI Alignment - why AI: might or might not kill us all",
    "section": "AI Timelines:",
    "text": "AI Timelines:\nEpoch provides and accessible intro to two compelling models and judgement-based forecasts."
  },
  {
    "objectID": "past-events/alignment/index.html#ai-risk-without-specific-countermeasures-the-easiest-path-to-transformative-ai-likely-leads-to-ai-takeover",
    "href": "past-events/alignment/index.html#ai-risk-without-specific-countermeasures-the-easiest-path-to-transformative-ai-likely-leads-to-ai-takeover",
    "title": "AI Alignment - why AI: might or might not kill us all",
    "section": "AI Risk: Without specific countermeasures, the easiest path to transformative AI likely leads to AI takeover",
    "text": "AI Risk: Without specific countermeasures, the easiest path to transformative AI likely leads to AI takeover\nResearch analyst Ajeya Cotra contends that misalignment is our default trajectory."
  },
  {
    "objectID": "past-events/alignment/index.html#ai-timelines-epoch",
    "href": "past-events/alignment/index.html#ai-timelines-epoch",
    "title": "AI Alignment - why AI: might or might not kill us all",
    "section": "AI Timelines: Epoch",
    "text": "AI Timelines: Epoch\nAn accessible intro to two compelling models and judgement-based forecasts."
  },
  {
    "objectID": "past-events/alignment/index.html#big-picture-recommendation-cold-takes-blog",
    "href": "past-events/alignment/index.html#big-picture-recommendation-cold-takes-blog",
    "title": "AI Alignment - why AI: might or might not kill us all",
    "section": "Big Picture Recommendation: Cold Takes blog",
    "text": "Big Picture Recommendation: Cold Takes blog\nAn accessible introduction to the worldview that informs Open Philanthropy’s long-term future grantmaking."
  },
  {
    "objectID": "past-events/alignment/index.html#cold-takes-blog",
    "href": "past-events/alignment/index.html#cold-takes-blog",
    "title": "AI Alignment - why AI: might or might not kill us all",
    "section": "Cold Takes blog",
    "text": "Cold Takes blog\nAn accessible introduction to the worldview that informs the philosophy of some of the people at the forefront of the effective altruism community."
  },
  {
    "objectID": "past-events/chatbots-guil/index.html",
    "href": "past-events/chatbots-guil/index.html",
    "title": "Developing Chatbots in an evolving AI landscape",
    "section": "",
    "text": "In this presentation, Guillaume described his process to becoming a senior chatbot engineer, the historic development of the field up until now, some chatbot terminology, and an overview of the technical challenges chatbot engineers face.\nClick here to see the presentation"
  },
  {
    "objectID": "past-events/eagle-eyes-search/index.html",
    "href": "past-events/eagle-eyes-search/index.html",
    "title": "Eagle Eyes Search",
    "section": "",
    "text": "At first glance - drones seem like the perfect tool for Search and Rescue (SAR) - they can fly over impassable terrain, see body heat, and survey large swaths of land in minutes. But ask any operator what it is like using a drone for SAR, they’ll tell you it is not easy. Many compare the task to finding the proverbial needle in a haystack.\nOn Thursday June 22, 6:30pm at The Common, we’ll dive into the problem and look inside one tool - Eagle Eyes (from a Squamish-based startup), that aims to find that needle.\nIn this deep-dive, we’ll go over the problem faced by SAR drone operators, and how to characterise it through the eyes of computer-vision / machine learning, and our approach to solving it so far. In a one-hour crash course, we’ll learn about precision, recall, false-positives, false-negatives, and the science, and art, of anomaly detection.\nFinally, we’ll open the floor for discussion. Feedback and ideas are most welcome! So whether you’re interested in SAR, machine learning, drones, or new technologies in general, come to learn and contribute to an exciting discussion."
  }
]