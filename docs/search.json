[
  {
    "objectID": "past-events/eagle-eyes-search/index.html",
    "href": "past-events/eagle-eyes-search/index.html",
    "title": "Eagle Eyes Search",
    "section": "",
    "text": "At first glance - drones seem like the perfect tool for Search and Rescue (SAR) - they can fly over impassable terrain, see body heat, and survey large swaths of land in minutes. But ask any operator what it is like using a drone for SAR, they’ll tell you it is not easy. Many compare the task to finding the proverbial needle in a haystack.\nOn Thursday June 22, 6:30pm at The Common, we’ll dive into the problem and look inside one tool - Eagle Eyes (from a Squamish-based startup), that aims to find that needle.\nIn this deep-dive, we’ll go over the problem faced by SAR drone operators, and how to characterise it through the eyes of computer-vision / machine learning, and our approach to solving it so far. In a one-hour crash course, we’ll learn about precision, recall, false-positives, false-negatives, and the science, and art, of anomaly detection.\nFinally, we’ll open the floor for discussion. Feedback and ideas are most welcome! So whether you’re interested in SAR, machine learning, drones, or new technologies in general, come to learn and contribute to an exciting discussion."
  },
  {
    "objectID": "past-events/chat-GPT-peter/index.html",
    "href": "past-events/chat-GPT-peter/index.html",
    "title": "Chat-GPT: The architecture behind the model",
    "section": "",
    "text": "There is a slideshow accompanying this section.\nSlideshow"
  },
  {
    "objectID": "past-events/collaborative-filtering/embeddings.html",
    "href": "past-events/collaborative-filtering/embeddings.html",
    "title": "Collaborative Filtering (AKA recommender systems)",
    "section": "",
    "text": "collaborative filtering\nHere’s a link to the accompanying slideshow for the embeddings section of the talk.\nThis meet took place at 6:30pm on Thursday 19th October, at the community futures office in valleycliffe (just across from the Backyard brew pub).  The rundown:  Peter gave a short talk on Tranformers - the transformative neural architecture behind ChatGPT, freaky-image-generators, and a bunch of other things.  Mike walked us through a blog he wrote on embeddings and collaborative filtering models (AKA Recommender Systems).  Afterwards we had discussion and a trip to the pub!"
  },
  {
    "objectID": "past-events/collaborative-filtering/embeddings.html#embeddings",
    "href": "past-events/collaborative-filtering/embeddings.html#embeddings",
    "title": "Collaborative Filtering (AKA recommender systems)",
    "section": "Embeddings",
    "text": "Embeddings\nSince there are hundreds of thousands of individual user IDs, and many more book titles, it will be useful to compress this data in some way - in a way which keeps the relevant information about each user and book, but doesn’t require the model to learn each individual user ID or book title. This is where Embeddings come in handy.\n\ndls = CollabDataLoaders.from_df(ratings, item_name='title', bs=16)"
  },
  {
    "objectID": "past-events/collaborative-filtering/embeddings.html#take-a-sample",
    "href": "past-events/collaborative-filtering/embeddings.html#take-a-sample",
    "title": "Collaborative Filtering (AKA recommender systems)",
    "section": "Take a sample",
    "text": "Take a sample\nTo speed up development and testing We’ll work with a random sample of 300,000 users from the dataset.\n\nnumber_of_samples = 300000\ndf=ratings.sample(number_of_samples)\ndls = CollabDataLoaders.from_df(df, item_name='title', bs=64)"
  },
  {
    "objectID": "past-events/collaborative-filtering/embeddings.html#sample-only-popular-books-and-users-with-lots-of-entries.",
    "href": "past-events/collaborative-filtering/embeddings.html#sample-only-popular-books-and-users-with-lots-of-entries.",
    "title": "Collaborative Filtering (AKA recommender systems)",
    "section": "Sample only popular books and users with lots of entries.",
    "text": "Sample only popular books and users with lots of entries.\nDeliberately selecting from the most read titles, and the most active readers could be a way of getting the information density up a little. This is definitely a design decision which should be scrutinized, since it biases the system towards more popular items, but it could be a good way to jumpstart training.\nPlus it doesn’t make a lot of sense to be training a collaborative filtering model on users who have read only one book: there wouldn’t be any second item to lookup and recommend for another user who has read the same book.\n\nbook_count = len(set(ratings.title))\npopular_books = ratings.title.value_counts()[:1000].keys()\n\nreader_count = len(set(ratings.user))\navid_readers = ratings.user.value_counts()[:1000].keys()\n\n\nlen(ratings)\n\n1031136\n\n\nOverwriting the variable dense_df with this new selection\n\ndense_df = ratings[ratings.title.isin(popular_books)]\ndense_df = (dense_df[dense_df.user.isin(avid_readers)])\nprint(len(dense_df))\n\n76402\n\n\nNow we’ve got the number of samples in the database down to 76402, and it only contains the top 1000 readers and the top 1000 books."
  },
  {
    "objectID": "past-events/collaborative-filtering/embeddings.html#make-a-new-dataloaders-object-to-draw-training-and-validation-samples-from-this-new-dataframe.",
    "href": "past-events/collaborative-filtering/embeddings.html#make-a-new-dataloaders-object-to-draw-training-and-validation-samples-from-this-new-dataframe.",
    "title": "Collaborative Filtering (AKA recommender systems)",
    "section": "Make a new dataloaders object to draw training and validation samples from this new dataframe.",
    "text": "Make a new dataloaders object to draw training and validation samples from this new dataframe.\n\ndense_dls = CollabDataLoaders.from_df(dense_df, item_name='title', bs=64)\nn_users = len(dense_dls.classes['user'])\nn_titles = len(dense_dls.classes['title'])\n\n\nmodel = DotProduct(n_users, n_titles, n_factors=50)"
  },
  {
    "objectID": "past-events/collaborative-filtering/embeddings.html#lets-see-how-the-model-trains-now",
    "href": "past-events/collaborative-filtering/embeddings.html#lets-see-how-the-model-trains-now",
    "title": "Collaborative Filtering (AKA recommender systems)",
    "section": "Let’s see how the model trains now",
    "text": "Let’s see how the model trains now\n\nlearn = Learner(dense_dls, model, loss_func=MSELossFlat())\nlearn.fit_one_cycle(5, 1e-3)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      time\n    \n  \n  \n    \n      0\n      0.175163\n      0.170583\n      00:06\n    \n    \n      1\n      0.129468\n      0.121618\n      00:07\n    \n    \n      2\n      0.106404\n      0.113181\n      00:06\n    \n    \n      3\n      0.098074\n      0.111734\n      00:06\n    \n    \n      4\n      0.094152\n      0.111598\n      00:06\n    \n  \n\n\n\n\nGreat - the training only takes 5s per epoch, and we’re still seeing convergence after 5 epochs. Let’s try to improve from here"
  },
  {
    "objectID": "past-events/collaborative-filtering/embeddings.html#thinking-about-latent-factors-as-components-of-a-vector-in-an-n-dimensional-feature-space",
    "href": "past-events/collaborative-filtering/embeddings.html#thinking-about-latent-factors-as-components-of-a-vector-in-an-n-dimensional-feature-space",
    "title": "Collaborative Filtering (AKA recommender systems)",
    "section": "Thinking about latent factors as components of a vector in an n-dimensional feature space",
    "text": "Thinking about latent factors as components of a vector in an n-dimensional feature space\nHere are the factors for each of the users in the batch:\n\nmodel.user_factors(batch[:,0])\n\ntensor([[ 0.0817, -0.0264,  0.0331,  ..., -0.0489,  0.0411, -0.0605],\n        [ 0.2433,  0.1127,  0.0474,  ..., -0.0423, -0.0127,  0.0787],\n        [ 0.0681, -0.0004, -0.0345,  ..., -0.0058, -0.0629, -0.0205],\n        ...,\n        [-0.0815,  0.0103, -0.0141,  ...,  0.0457,  0.0288,  0.0169],\n        [-0.0230,  0.0015, -0.0673,  ..., -0.0892,  0.0012, -0.0144],\n        [-0.0735, -0.1434, -0.0621,  ...,  0.0003,  0.0648,  0.1412]],\n       device='cuda:0', grad_fn=<EmbeddingBackward0>)\n\n\nEach of these numbers represents a learned latent factor for that user. The latent factors can can be thought of as the contribution / component to a vector in n-dimensional space, where each number is a different axis’s contribution. The factors are all orthoganal to oneanother. They can represent things like taste, genre, age etc.\nFor example: if user A has 3 latent factors x, y, z, and these have values 1, 0.2, -0.9, then we can imagine a vector in 3d space which extends along the x dimension by 1, along y by 0.2, and extends negatively along the z dimension by 1.\nAnother user, or book title, might point in a very similar direction. This would mean that their factors overlap a lot and tend not to cancel out.\nEach of these dimensions could code for something like ‘enjoys horror books’, ‘enjoys shorter books’, younger.\nIf there was another user who’s factors were -1, 0.2, 1, we might say that they had the opposite taste for horror stories, that they have the same liking for shorter books, and that they are older.\nThe latent factors encode for real world meaning, but the factors themselves aren’t chosen by the engineer when setting up the neural network - rather they emerge from the relationships between books, users and ratings as the model trains."
  },
  {
    "objectID": "past-events/collaborative-filtering/embeddings.html#finding-the-books-with-the-highest-bias",
    "href": "past-events/collaborative-filtering/embeddings.html#finding-the-books-with-the-highest-bias",
    "title": "Collaborative Filtering (AKA recommender systems)",
    "section": "Finding the books with the highest bias",
    "text": "Finding the books with the highest bias\nHere’s a list of books with a high bias: they end up having a higher rating across the board, despite the specific features which were learned to describe the books. Intuitively this means that they’re high quality - since they get consistently high ratings despite their genre and the users’ tastes.\n\nbooks_bias = learn.model.title_bias.weight.squeeze()\nidxs = books_bias.argsort(descending=True)[:20]\n[dense_dls.classes['title'][i] for i in idxs]\n\n['Harry Potter and the Prisoner of Azkaban (Book 3)',\n \"Harry Potter and the Sorcerer's Stone (Book 1)\",\n 'Harry Potter and the Chamber of Secrets (Book 2)',\n 'To Kill a Mockingbird',\n 'Harry Potter and the Order of the Phoenix (Book 5)',\n 'The Secret Garden',\n 'A Wrinkle in Time',\n \"Harry Potter and the Sorcerer's Stone (Harry Potter (Paperback))\",\n 'Harry Potter and the Goblet of Fire (Book 4)',\n 'The Fellowship of the Ring (The Lord of the Rings, Part 1)',\n 'The Little Prince',\n 'Fahrenheit 451',\n \"Where the Heart Is (Oprah's Book Club (Paperback))\",\n 'Lord of the Flies',\n 'The Lovely Bones: A Novel',\n 'Anne Frank: The Diary of a Young Girl',\n 'The Color Purple',\n \"The Handmaid's Tale\",\n 'One for the Money (A Stephanie Plum Novel)',\n 'The Da Vinci Code']"
  },
  {
    "objectID": "past-events/elliot-geospatial/index.html",
    "href": "past-events/elliot-geospatial/index.html",
    "title": "Geospatial 101",
    "section": "",
    "text": "Elliot gave an excellent 101 class on processing geospatial data for data scientists who haven’t worked on that kind of data before.\nHe outlined some of the things you should be aware of, so if and when you deal with that kind of data yourself, you know how to diagnose the problems and search for what you need to solve the issues you’re facing.\nThanks for putting this together Elliot!\nslides\nCheck out the notebook from this talk!"
  },
  {
    "objectID": "past-events/eric-quantum-ml/index.html",
    "href": "past-events/eric-quantum-ml/index.html",
    "title": "Eric’s talk on Quantum ML",
    "section": "",
    "text": "This was a fascinating talk on quantum physics, quantum computing and some applications of machine learning within all of this. Check out the slideshow here:\npdf slides"
  },
  {
    "objectID": "past-events/numpy-peter/numpy-tutorial.html",
    "href": "past-events/numpy-peter/numpy-tutorial.html",
    "title": "Numpy deep dive",
    "section": "",
    "text": "numpylogo\nThis evening Peter hosted a talk on NumPy, a python numeric processing package which runs on C under the hood.\nPeter made a notebook accompanying this talk; check it out here! notebook"
  },
  {
    "objectID": "past-events/numpy-peter/numpy-tutorial.html#goal-of-this-lecture",
    "href": "past-events/numpy-peter/numpy-tutorial.html#goal-of-this-lecture",
    "title": "Numpy deep dive",
    "section": "Goal of this lecture",
    "text": "Goal of this lecture\n\nGet everyone familiar with the basics of array-manipulation.\nMake sure even those people already familiar learn something new.\nIntroduce pytorch from the bottom-up."
  },
  {
    "objectID": "past-events/numpy-peter/numpy-tutorial.html#array-libraries---what-are-they",
    "href": "past-events/numpy-peter/numpy-tutorial.html#array-libraries---what-are-they",
    "title": "Numpy deep dive",
    "section": "Array libraries - what are they?",
    "text": "Array libraries - what are they?\nLibraries like Numpy, PyTorch, and Tensorflow use N-dimensional arrays as a basic datatype. They allow you to manipulate arrays much more compactily and faster than if you were to use native python. Behind the scenes, they do all the looping in C - which will typically be around 20-100x faster than doing it in python.\n\nfrom timeit import timeit\nt1=timeit(\"sum(ai*bi for ai, bi in zip(a, b))\", setup=\"import random; N=10000000; a=[random.gauss(0, 1) for _ in range(N)]; b=[random.gauss(0, 1) for _ in range(N)]\", number = 10)\nt2=timeit(\"(a*b).sum()\", setup=\"import numpy as np; N=10000000; a, b = np.random.randn(2, N)\", number = 10)\nprint(f\"With python looping: t={t1:.3f}, with numpy looping: t={t2:.3f}.  Speedup factor: {t1/t2:.0f}x\")\n\nWith python looping: t=9.208, with numpy looping: t=0.352.  Speedup factor: 26x"
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html",
    "href": "past-events/git-walkthrough/git-walkthrough.html",
    "title": "Version Control 101",
    "section": "",
    "text": "In this double feature, Mike walked us through how to get set up using Git, then Peter showed us Github Co-pilot, an AI based code completion tool which runs in your editor. This was a group coding session with input from other members of the community.\ngit intro\npeter’s co-pilot presentation"
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#git-github-and-github-co-pilot-tutorial-evening",
    "href": "past-events/git-walkthrough/git-walkthrough.html#git-github-and-github-co-pilot-tutorial-evening",
    "title": "Version Control 101",
    "section": "Git, GitHub and GitHub Co-Pilot tutorial evening",
    "text": "Git, GitHub and GitHub Co-Pilot tutorial evening\nCommunity coding event. This Wednesday 7th June to The Common, Cleveland Ave.\nCome along at 6:30 if you already have Git installed, or 6pm if you don’t and would like some help getting set up.\n\n\nIn this tutorial we’ll get set up using Git in the terminal then talk about how to fix things when they go wrong.\n\n\nWe’ll start by going through some of the most common Git commands in the terminal, then we’ll move on to using GitHub and Co-Pilot later in the evening.\n\n\nIf you are totally new to Git and you don’t have Git set up on your computer, then come along at 6:00 instead of 6:30 to get set up."
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#get-online",
    "href": "past-events/git-walkthrough/git-walkthrough.html#get-online",
    "title": "Version Control 101",
    "section": "Get online",
    "text": "Get online\nusername:\npassword:"
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#install-git",
    "href": "past-events/git-walkthrough/git-walkthrough.html#install-git",
    "title": "Version Control 101",
    "section": "install git",
    "text": "install git\n\nLinux:\nhead to terminal and enter sudo dnf install git-all\n\n\nMac OS:\nopen Terminal and enter $ git --version then follow prompts to install.\nIf you don’t have XCode tools installed, you might need to install homebrew, then once that’s setup type brew install git\n\n\nWindows:\ndownload and install from https://git-scm.com/download/win\nHaving trouble?\nPoke around here https://git-scm.com/book/en/v2/Getting-Started-Installing-Git\nGoogle or check stack overflow\nAsk for help if someone is free!"
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#making-a-different-branch",
    "href": "past-events/git-walkthrough/git-walkthrough.html#making-a-different-branch",
    "title": "Version Control 101",
    "section": "Making a different branch",
    "text": "Making a different branch\nWe’re currently on the master branch. We could make some changes on a different branch and the original branch will remain unchanged until we merge the brances back together later. Let’s try this! \ngit branch ellys-edit\ngit checkout ellys-edit\n\ngit branch\n\nThe green text indicates the branch we’re currently on\nNow we’re on the new branch, let’s make some changes.\nIn this scenario, Elly has been given the task of arranging food for the trip. She creates a new file called food.txt and populates it with important food supplies.\nWhile she’s at it, she realizes that the forecast is for cloud and rain, so she removes sunscreen and sunglasses from the original packing list.\nFinally, she renames the README file to gear.txt \nHere’s what the changes look like in the terminal \nTo commit these changes to the master branch, we can run git add . then commit the changes."
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#switching-between-branches",
    "href": "past-events/git-walkthrough/git-walkthrough.html#switching-between-branches",
    "title": "Version Control 101",
    "section": "Switching between branches",
    "text": "Switching between branches\nBy typing git checkout master and git checkout ellys-branch we can switch between branches. This changes the contents of the directory - have a play with it with the directory open."
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#merging-two-branches",
    "href": "past-events/git-walkthrough/git-walkthrough.html#merging-two-branches",
    "title": "Version Control 101",
    "section": "Merging two branches",
    "text": "Merging two branches\nTo merge the changes from another branch, into the one we’re currently on, we can use git merge ellys-edit from the master branch."
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#merge-conflict",
    "href": "past-events/git-walkthrough/git-walkthrough.html#merge-conflict",
    "title": "Version Control 101",
    "section": "merge conflict",
    "text": "merge conflict\nMaking edits like this works most of the time, but sometimes we have a conflict, for example when someone edits the same line as code as you - and it isn’t obvious how to merge these edits. In this case we’ll see an error message and we’ll be asked which edit to keep.\nLet’s check this out by supposing that I want to save weight by replacing the beer with an empty water bottle, and Elly wants to take it to the next level by ditching the burgers, and adding more beer…\nI’ve changed to the respective branches and made the edits to this, and committed the changes on each branch.\nLook at the git log on each branch to see what was done. \nand on ellys-edit:"
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#lets-try-a-git-merge",
    "href": "past-events/git-walkthrough/git-walkthrough.html#lets-try-a-git-merge",
    "title": "Version Control 101",
    "section": "Let’s try a git merge:",
    "text": "Let’s try a git merge:\n\nGit status gives us more info on the merge conflict - both the branches being merged attempt to modify the same file."
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#git-diff",
    "href": "past-events/git-walkthrough/git-walkthrough.html#git-diff",
    "title": "Version Control 101",
    "section": "Git diff",
    "text": "Git diff\ngit diff shows us the difference between the commits, and where the conflict exists. !\n\nWe have a couple of ways to deal with this - we can abort the merge using git merge --abort and use a new command such as git merge --strategy-option ours\nOr we can edit the conflicting file partway through the merge. To do this, head to the file in conflict, and remove all the <<<<<<< HEAD, ======= and >>>>>>> ellys-edit sections, then leave the file as you’d like it in the final merged version.\n\nAt this point I’ve gone ahead and opened up food.txt in a text editor, and left it how I’d like the final version to be. Let’s see how things look in the terminal.\n\nGreat! We’ve installed Git, made a project, edited the project on different branches, done a git merge, and learnt to resolve merge conflicts.\nWhat if we made one or more commits, and later realize that the commit broke a section of code? This is where git revert comes to the rescue."
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#git-revert",
    "href": "past-events/git-walkthrough/git-walkthrough.html#git-revert",
    "title": "Version Control 101",
    "section": "git revert",
    "text": "git revert\n\nmakes a new commit which is the inverse operation of an existing commit.\nIt allows you to undo the effect of a commit, but still keeps the data which broke your code in case you need to go back.\nthis is also useful to avoid undoing history which other people may have branched off of.\nIf applying the inverse operation of a commit creates merge conflicts, the revert method will fail.\n\nto use git revert, you can either use\ngit revert head\nto rewind by 1 commit.\nor\ngit revert # where the # is the commit hash.\ngit log"
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#interactive-rebase",
    "href": "past-events/git-walkthrough/git-walkthrough.html#interactive-rebase",
    "title": "Version Control 101",
    "section": "interactive rebase",
    "text": "interactive rebase\nSometimes a git-revert isn’t what you need: I once had an issue when trying to push very large files to GitHub. I was a few commits ahead before I decided to sync my project with the company’s github repo, at which point I found that some files exceeded the remote server’s maximum filesize. I used git revert to selectively remove these large files, adding them to a .gitignore as I went.\ninteractive rebase allows you to cycle through multiple commits, picking and choosing which parts of which commits are applied:\n\nTo see the hashes of the commits:\n\ngit log --all --decorate --oneline\n\nand find the commit hash of the last good commit hash before mistake was made.\nthen do an interactive rebase from that point on: let’s say we’re wanting to edit the July 4th commit:\ngit rebase -i 6fae677\na prompt will pop up asking which commits you want to edit and which ones you want to keep unchanged.\nNote on vim: If this opens up in vim, you’ll need to be in Insert mode by pressing esc I, then once you finish editing using esc : wq then hit return.\nAt first all of the commits will say pick in front of them. Change this to edit for the ones you want to modify.\nSave the file first then follow the prompts to cycle through the commits one by one.\nFrom here you’ll need to create a series of commits using\ngit status\nthen edit, add, remove any files which you need in that commit\nAlso resolve any merge conflicts as you go through\nOnce everything is correct for that commit, use\ngit rebase --continue\nto move on to the next commit.\nOnce you’ve cycled through to the last commit, the git rebase is finished."
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#cloning-and-pull-requests",
    "href": "past-events/git-walkthrough/git-walkthrough.html#cloning-and-pull-requests",
    "title": "Version Control 101",
    "section": "cloning and pull requests",
    "text": "cloning and pull requests\nUsing Git and GitHub we can easily copy (pull) an enitre code repository to our local machine, make an edit, then create a request for our edit to be merged back into the original codebase. This is called a Pull Request."
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#ssh-keys",
    "href": "past-events/git-walkthrough/git-walkthrough.html#ssh-keys",
    "title": "Version Control 101",
    "section": "SSH Keys",
    "text": "SSH Keys\nOne of the things you’ll encounter getting your computer talking to GitHub, is setting up an SSH key. This can be quite fiddly, and we don’t have time to go into it in this tutorial - but if you encounter this then here’s a guide on setting up an SSH key on the GitHub website: https://docs.github.com/en/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account"
  },
  {
    "objectID": "past-events/git-walkthrough/git-walkthrough.html#cloning-an-existing-project-on-github",
    "href": "past-events/git-walkthrough/git-walkthrough.html#cloning-an-existing-project-on-github",
    "title": "Version Control 101",
    "section": "Cloning an existing project on GitHub",
    "text": "Cloning an existing project on GitHub\nOnce you’ve got SSH keys setup and working, this is as easy as typing\ngit clone followed by the address of the repo on GitHub\n\nAny changes you make will be local changes, until you commit and push the changes. Pushing the changes will attempt to push back to the repository which was cloned - so if you want to keep your own version of the project separate, you’ll want to fork the repository before cloning it."
  },
  {
    "objectID": "past-events/intro-to-ml-mike/index.html",
    "href": "past-events/intro-to-ml-mike/index.html",
    "title": "Intro to machine learning",
    "section": "",
    "text": "This evening was an overview of machine learning for the benefit of newcomers, or people working in related fields.\nClick here to see the slideshow which accompanied the talk"
  },
  {
    "objectID": "past-events/chatbots-guil/index.html",
    "href": "past-events/chatbots-guil/index.html",
    "title": "Developing Chatbots in an evolving AI landscape",
    "section": "",
    "text": "In this presentation, Guillaume described his process to becoming a senior chatbot engineer, the historic development of the field up until now, some chatbot terminology, and an overview of the technical challenges chatbot engineers face.\nClick here to see the presentation"
  },
  {
    "objectID": "past-events/whale-health-hackday/index.html",
    "href": "past-events/whale-health-hackday/index.html",
    "title": "Whale Health Hackday",
    "section": "",
    "text": "We hosted a hackathon to try to find a way to measure and detect whales from drone footage. 7 people attended. We tried a few methods and everybody learnt something new. There was even pizza and beer!\nCheck out the writeup!\nGitHub for this event"
  },
  {
    "objectID": "past-events/from-scratch-model-mike/boats-example.html",
    "href": "past-events/from-scratch-model-mike/boats-example.html",
    "title": "From scratch model part 2: training an image recognition model using fastai",
    "section": "",
    "text": "In this presentation Mike walked us through how to train an image classifier using the fastai library. This was a group coding session from no-code to a working model."
  },
  {
    "objectID": "past-events/from-scratch-model-mike/boats-example.html#most-of-this-notebook-is-adapted-from-the-fast.ai-course-material-link-here",
    "href": "past-events/from-scratch-model-mike/boats-example.html#most-of-this-notebook-is-adapted-from-the-fast.ai-course-material-link-here",
    "title": "From scratch model part 2: training an image recognition model using fastai",
    "section": "Most of this notebook is adapted from the fast.ai course material, link here",
    "text": "Most of this notebook is adapted from the fast.ai course material, link here\n\nNotebook Tips\n\ntype ? or ?? next to a function then shift + return to execute the cell to get the source code.\nPress shift + tab inside function’s parentheses to get function signature and docstring\nType the name of a module and hit enter to get info about its type and location."
  },
  {
    "objectID": "past-events/from-scratch-model-mike/boats-example.html#change-your-code-to-reflect-the-categories-youre-using.",
    "href": "past-events/from-scratch-model-mike/boats-example.html#change-your-code-to-reflect-the-categories-youre-using.",
    "title": "From scratch model part 2: training an image recognition model using fastai",
    "section": "Change your code to reflect the categories you’re using.",
    "text": "Change your code to reflect the categories you’re using.\n\nboat_types = 'canoe', 'kayak', 'sailboat'\n\n\npath = Path('boats')\n\nDownload images from chosen categories.\nThis cell may take a few minutes to run\n\nif not path.exists():\n    path.mkdir()\n    for boat in boat_types:\n        dest = (path/boat)\n        dest.mkdir(exist_ok=True)\n        results = search_images(boat)\n        download_images(dest, urls=results)\n\n\n!ls {path}\npath\n\ncanoe  kayak  sailboat\n\n\nPath('boats')\n\n\n\nfilenames = get_image_files(path)\nfilenames\n\n(#554) [Path('boats/sailboat/3b873c96-0d1f-4404-9aae-af25d3805177.jpg'),Path('boats/sailboat/6336c57d-8ad9-4318-836c-fba58b5357be.jpg'),Path('boats/sailboat/d2a981d0-0d3e-4b0e-a077-a5cbda1a41b0.JPG'),Path('boats/sailboat/da7dc60e-7c83-4807-9fc1-a0f5061a5080.jpg'),Path('boats/sailboat/168643af-803b-4783-8c6b-a785157c481e.jpeg'),Path('boats/sailboat/f4055206-199c-42a8-bf74-8ed6c4dc7e08.jpg'),Path('boats/sailboat/d5883260-5325-41cb-a645-016051c37819.jpg'),Path('boats/sailboat/4b44e5d8-75e1-413b-a9b9-bd3f19b63df4.jpg'),Path('boats/sailboat/86d8f1b9-b75b-467f-8476-2d91805a150b.jpg'),Path('boats/sailboat/e07b4c1d-a717-4c10-9059-005016798081.jpeg')...]\n\n\n\nfailed = verify_images(filenames)\n\n\nfailed\n\n(#0) []\n\n\n\nfailed.map(Path.unlink)\n\n(#0) []\n\n\n\nfailed\n\n(#0) []"
  },
  {
    "objectID": "past-events/from-scratch-model-mike/boats-example.html#create-a-way-to-load-datasets-and-dataloaders",
    "href": "past-events/from-scratch-model-mike/boats-example.html#create-a-way-to-load-datasets-and-dataloaders",
    "title": "From scratch model part 2: training an image recognition model using fastai",
    "section": "Create a way to load datasets and dataloaders",
    "text": "Create a way to load datasets and dataloaders\n\nboats = DataBlock(\n    blocks=(ImageBlock, CategoryBlock),\n    get_items=get_image_files,\n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128)\n)\n\n\ndataloaders = boats.dataloaders(path)\n\n\ndataloaders.device\n\ndevice(type='cuda', index=0)\n\n\nIf the device type is ‘cuda’ that means we’ve got the model on the GPU. If device type is ‘cpu’ then now’s a good time to see if there is a free GPU instance available. The data you downloaded earlier won’t be lost since Paperspace has persistent storage.\n\n# Docs for some modules. Uncomment as required. \n# DataLoader?\n# DataLoaders?\n# Datasets?\n# torch.utils.data.Dataset?\n# torch.utils.data.DataLoader?"
  },
  {
    "objectID": "past-events/from-scratch-model-mike/boats-example.html#training-and-validation-sets",
    "href": "past-events/from-scratch-model-mike/boats-example.html#training-and-validation-sets",
    "title": "From scratch model part 2: training an image recognition model using fastai",
    "section": "Training and validation sets",
    "text": "Training and validation sets\nOur data is split into training and validation batches. 20% of the data is in the validation set, and 80% is in the training set.\nDataset: an iterable over tuples containing images with their corresponding category.  DataLoader: a PyTorch iterable returning a batch of datasets. DataLoaders: a fastai iterable which splits dataloaders into training and validation datasets.\n\ndataloaders.train.show_batch()"
  },
  {
    "objectID": "past-events/from-scratch-model-mike/boats-example.html#train-a-model",
    "href": "past-events/from-scratch-model-mike/boats-example.html#train-a-model",
    "title": "From scratch model part 2: training an image recognition model using fastai",
    "section": "Train a model",
    "text": "Train a model\n\nlearn = vision_learner(dataloaders, resnet18, metrics=error_rate)\nlearn.fine_tune(4)\nlearn.recorder.plot_loss()\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      1.512921\n      0.358238\n      0.145455\n      00:13\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.609499\n      0.233965\n      0.100000\n      00:13\n    \n    \n      1\n      0.459157\n      0.267047\n      0.118182\n      00:13\n    \n    \n      2\n      0.373013\n      0.286165\n      0.118182\n      00:13\n    \n    \n      3\n      0.338020\n      0.260390\n      0.109091\n      00:13"
  },
  {
    "objectID": "past-events/alignment/index.html",
    "href": "past-events/alignment/index.html",
    "title": "AI Alignment - why AI: might or might not kill us all",
    "section": "",
    "text": "Ilva gave a great introduction to the subject of AI alignment and some resources for further reading, providing an opportunity for our community to get together and share knowledge, speculate, and debate this topic."
  },
  {
    "objectID": "past-events/alignment/index.html#cold-takes-blog",
    "href": "past-events/alignment/index.html#cold-takes-blog",
    "title": "AI Alignment - why AI: might or might not kill us all",
    "section": "Cold Takes blog",
    "text": "Cold Takes blog\nAn accessible introduction to the worldview that informs the philosophy of some of the people at the forefront of the effective altruism community."
  },
  {
    "objectID": "past-events/alignment/index.html#ai-timelines-epoch",
    "href": "past-events/alignment/index.html#ai-timelines-epoch",
    "title": "AI Alignment - why AI: might or might not kill us all",
    "section": "AI Timelines: Epoch",
    "text": "AI Timelines: Epoch\nAn accessible intro to two compelling models and judgement-based forecasts."
  },
  {
    "objectID": "past-events/alignment/index.html#ai-risk-without-specific-countermeasures-the-easiest-path-to-transformative-ai-likely-leads-to-ai-takeover",
    "href": "past-events/alignment/index.html#ai-risk-without-specific-countermeasures-the-easiest-path-to-transformative-ai-likely-leads-to-ai-takeover",
    "title": "AI Alignment - why AI: might or might not kill us all",
    "section": "AI Risk: Without specific countermeasures, the easiest path to transformative AI likely leads to AI takeover",
    "text": "AI Risk: Without specific countermeasures, the easiest path to transformative AI likely leads to AI takeover\nResearch analyst Ajeya Cotra contends that misalignment is our default trajectory."
  },
  {
    "objectID": "past-events/past-events.html",
    "href": "past-events/past-events.html",
    "title": "Past events",
    "section": "",
    "text": "Whale Health Hackday\n\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2024\n\n\nML Squamish\n\n\n\n\n\n\n  \n\n\n\n\nCollaborative Filtering (AKA recommender systems)\n\n\n\n\n\n\n\n\n\n\n\n\nOct 19, 2023\n\n\nMike Gallimore\n\n\n\n\n\n\n  \n\n\n\n\nEagle Eyes Search\n\n\n\n\n\nComputer vision for drones for SAR\n\n\n\n\n\n\nJun 22, 2023\n\n\nPeter O’Connor\n\n\n\n\n\n\n  \n\n\n\n\nVersion Control 101\n\n\n\n\n\n\n\n\n\n\n\n\nJun 7, 2023\n\n\nMike Gallimore & Peter O’Connor\n\n\n\n\n\n\n  \n\n\n\n\nAI Alignment - why AI: might or might not kill us all\n\n\n\n\n\n\n\n\n\n\n\n\nMay 24, 2023\n\n\nIlva Ravinska\n\n\n\n\n\n\n  \n\n\n\n\nDeveloping Chatbots in an evolving AI landscape\n\n\n\n\n\n\n\n\n\n\n\n\nMay 10, 2023\n\n\nGuillaumen Slevan-Tremblay\n\n\n\n\n\n\n  \n\n\n\n\nGeospatial 101\n\n\n\n\n\n\n\n\n\n\n\n\nMar 22, 2023\n\n\nElliot Salisbury\n\n\n\n\n\n\n  \n\n\n\n\nEric’s talk on Quantum ML\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\nEric Drechsler\n\n\n\n\n\n\n  \n\n\n\n\nFrom scratch model part 2: training an image recognition model using fastai\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 8, 2023\n\n\nMike Gallimore\n\n\n\n\n\n\n  \n\n\n\n\nFrom Scratch Model part 1: Getting set up with a free cloud machine learning environment in six easy steps\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 8, 2023\n\n\nMike Gallimore\n\n\n\n\n\n\n  \n\n\n\n\nIntro to machine learning\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 1, 2023\n\n\nMike Gallimore\n\n\n\n\n\n\n  \n\n\n\n\nChat-GPT: The architecture behind the model\n\n\n\n\n\n\n\n\n\n\n\n\nJan 11, 2023\n\n\nPeter O’Connor\n\n\n\n\n\n\n  \n\n\n\n\nNumpy deep dive\n\n\n\n\n\n\n\n\n\n\n\n\nDec 21, 2022\n\n\nPeter O’Connor\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "past-events/paperspace-setup-mike/paperspace.html",
    "href": "past-events/paperspace-setup-mike/paperspace.html",
    "title": "From Scratch Model part 1: Getting set up with a free cloud machine learning environment in six easy steps",
    "section": "",
    "text": "This is part 1 of Mike’s model from scratch presentation. This was a group coding session from no-code to a working model. This notebook walks through how to get set up with a free cloud computer capable of running machine learning code on a GPU."
  },
  {
    "objectID": "past-events/paperspace-setup-mike/paperspace.html#getting-set-up-with-paperspace-gradient-in-six-easy-steps",
    "href": "past-events/paperspace-setup-mike/paperspace.html#getting-set-up-with-paperspace-gradient-in-six-easy-steps",
    "title": "From Scratch Model part 1: Getting set up with a free cloud machine learning environment in six easy steps",
    "section": "Getting set up with Paperspace Gradient in six easy steps",
    "text": "Getting set up with Paperspace Gradient in six easy steps"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to our landing page",
    "section": "",
    "text": "Next meetup Tuesday 7th January 2205!\nWe’ll be doing lightning talks at the Easy Expense offices on 2nd Ave.\nIf you’ve been working on anythin new this year, or tried out any new technologies, come along and let us know about it.\n\n\nCheck out our past events\n\n\nAnd join our Slack channel.\nShoot us an email to get an invite"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "We are a group of Squamish residents connected over a common interest in machine learning, data science and AI.\nWe aim to grow skills and knowledge, and make connections through a series of talks, group coding events, pair programming and hackathons.\nWe aim to provide a place for people to share knowledge in the domains of data science, machine learning and artificial intelligence. We try to structure our talks to be as participatory as possible - rather than just a lecture on a topic, we encourage input and material from our members, and encourage debate in the hope that this stimulates learning and growth of our members.\nTake a look at our vision statement\nTo get involved, come along on Wednesday evenings to meet the group!\nIf you’d like to join our Slack messenger channel, or if you have any questions, you can shoot us an email here: mlsquamish@gmail.com\nWe host our meets at the offices of Easy Expense - a local tech company with an amazing expense tracking app. Check out their website and download their app on IOS or Android."
  }
]