{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9a9eca33",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Collaborative Filtering (AKA recommender systems)\"\n",
    "author: \"Mike Gallimore\"\n",
    "date: \"2023-10-19\"\n",
    "categories: [embeddings, collaborative filtering, reccomender systems, talk, neural nets, deep learning, presentation]\n",
    "image: \"\"\n",
    "render: false\n",
    "---\n",
    "\n",
    "![collaborative filtering](collaborative-filtering.png)\n",
    "\n",
    "[Here's a link to the accompanying slideshow for the embeddings section of the talk.](https://docs.google.com/presentation/d/1iIenJ7EvGZ9eL78jrr2KaQrxJtQNCV-UuILmdFUISWs/edit?usp=sharing)\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "This meet took place at 6:30pm on Thursday 19th October, at the community futures office in valleycliffe (just across from the Backyard brew pub).\n",
    "<br>\n",
    "The rundown:\n",
    "<br>\n",
    "Peter gave a short talk on Tranformers - the transformative neural architecture behind ChatGPT, freaky-image-generators, and a bunch of other things.\n",
    "<br>\n",
    "Mike walked us through a blog he wrote on embeddings and collaborative filtering models (AKA Recommender Systems).\n",
    "<br>\n",
    "Afterwards we had discussion and a trip to the pub! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223e98d1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.018224,
     "end_time": "2023-07-19T01:32:02.691470",
     "exception": false,
     "start_time": "2023-07-19T01:32:02.673246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# What is an embedding layer and how does it work?\n",
    "In this example I'll make a collaborative filtering model (recommender system) which uses an entity embedding as part of a system for recommending books to users. \n",
    "\n",
    "Embeddings are a neat way to take a large number of individual items (users, products, locations for example), and represent each item using an n-dimensional vector instead of using its unique id. At first this might sound like it would increase the size and complexity of the model - since each item now needs an additional vector representation - but in fact this process reduces the number of individual inputs the model needs to see to be able to make predictions. \n",
    "\n",
    "For example, if we had an embedding for 1000 book titles, without an embedding layer the model would need to see each unique ID and learn the difference between them. An embedding vector for each of these book titles might be 2 dimensions deep, and might encode for each book's sci-fi-ness and its length. This means we could feed this two dimensional embedding vector as input to the model rather than the 1000 individual titles. Since those inputs represent something real about the book, that might be enough information to make sensible predictions with. In a sense the embedding compresses information about each of the N inputs into an n dimensional vector. \n",
    "\n",
    "In this blog post I'll follow a similar process to the one outlined in the fast.ai course which used the movielens dataset. I'll aim to explain some nuances about embedding layers, since I found this concept pretty confusing at first. Now that I've got my head around them I'm pretty amazed at how elegant, powerful and useful embeddings can be, and I'm excited to start trying out creative uses for embeddings. \n",
    "\n",
    "Read more on embeddings in this paper: [Guo, Cheng et al. “Entity Embeddings of Categorical Variables”](https://arxiv.org/pdf/1604.06737.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb6ff573",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:32:02.729122Z",
     "iopub.status.busy": "2023-07-19T01:32:02.728538Z",
     "iopub.status.idle": "2023-07-19T01:32:07.250591Z",
     "shell.execute_reply": "2023-07-19T01:32:07.249581Z"
    },
    "papermill": {
     "duration": 4.543733,
     "end_time": "2023-07-19T01:32:07.253239",
     "exception": false,
     "start_time": "2023-07-19T01:32:02.709506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from fastai.collab import *\n",
    "from fastai.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c48076ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:32:07.293634Z",
     "iopub.status.busy": "2023-07-19T01:32:07.291563Z",
     "iopub.status.idle": "2023-07-19T01:32:07.297822Z",
     "shell.execute_reply": "2023-07-19T01:32:07.296722Z"
    },
    "papermill": {
     "duration": 0.027844,
     "end_time": "2023-07-19T01:32:07.299991",
     "exception": false,
     "start_time": "2023-07-19T01:32:07.272147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_all(df):\n",
    "    with pd.set_option('display.max_columns', 0, 'display.max_rows', 0):\n",
    "        print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aba439b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:32:07.338979Z",
     "iopub.status.busy": "2023-07-19T01:32:07.338131Z",
     "iopub.status.idle": "2023-07-19T01:32:07.342854Z",
     "shell.execute_reply": "2023-07-19T01:32:07.341998Z"
    },
    "papermill": {
     "duration": 0.025938,
     "end_time": "2023-07-19T01:32:07.344931",
     "exception": false,
     "start_time": "2023-07-19T01:32:07.318993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = Path('/kaggle/input/book-recommendation-dataset/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7c0cc2",
   "metadata": {
    "papermill": {
     "duration": 0.017455,
     "end_time": "2023-07-19T01:32:07.380761",
     "exception": false,
     "start_time": "2023-07-19T01:32:07.363306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading the data into Pandas\n",
    "It doesn't look like much, but the Ratings.csv file contains all the data we need to train a collaborative filtering model: a user column, the ISBN of a book, and the rating a user gave for that book. \n",
    "\n",
    "It will be easier for us to understand if we can replace the book's ISBN with its title, so the Books.csv file is used to find the titles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a95bb8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:32:07.419002Z",
     "iopub.status.busy": "2023-07-19T01:32:07.418102Z",
     "iopub.status.idle": "2023-07-19T01:32:11.149606Z",
     "shell.execute_reply": "2023-07-19T01:32:11.148679Z"
    },
    "papermill": {
     "duration": 3.753023,
     "end_time": "2023-07-19T01:32:11.151791",
     "exception": false,
     "start_time": "2023-07-19T01:32:07.398768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating\n",
       "0   276725  034545104X            0\n",
       "1   276726  0155061224            5\n",
       "2   276727  0446520802            0\n",
       "3   276729  052165615X            3\n",
       "4   276729  0521795028            6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(path/'Ratings.csv')\n",
    "books = pd.read_csv(path/'Books.csv', low_memory=False)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9454ee64",
   "metadata": {
    "papermill": {
     "duration": 0.017628,
     "end_time": "2023-07-19T01:32:11.187781",
     "exception": false,
     "start_time": "2023-07-19T01:32:11.170153",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Scaling\n",
    "Here I'm dividing all the ratings by 10 so they all lie between 0 and 1 instead of 0 and 10. I wanted to see what effect this had on the loss during training. It reduced the loss by an order of magnitude. This isn't a meaningful increase in accuracy - it just means that the size of the errors is correspondingly lower since we're operating within a smaller target range. Regarless I decided to keep the ratings scaled between 0 and 1 since I think it's just as easy to understand this scale, plus there might be some benefit to this for models with more features. [Click here to read more about scaling.](\n",
    "https://developers.google.com/machine-learning/crash-course/representation/cleaning-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ebc6ef9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:32:11.224567Z",
     "iopub.status.busy": "2023-07-19T01:32:11.224242Z",
     "iopub.status.idle": "2023-07-19T01:32:11.239683Z",
     "shell.execute_reply": "2023-07-19T01:32:11.238744Z"
    },
    "papermill": {
     "duration": 0.036479,
     "end_time": "2023-07-19T01:32:11.241933",
     "exception": false,
     "start_time": "2023-07-19T01:32:11.205454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratings['Book-Rating']=ratings['Book-Rating'].divide(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f46c60e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:32:11.279488Z",
     "iopub.status.busy": "2023-07-19T01:32:11.279171Z",
     "iopub.status.idle": "2023-07-19T01:32:12.364185Z",
     "shell.execute_reply": "2023-07-19T01:32:12.363194Z"
    },
    "papermill": {
     "duration": 1.106685,
     "end_time": "2023-07-19T01:32:12.367070",
     "exception": false,
     "start_time": "2023-07-19T01:32:11.260385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.01.THUMBZZZ.jpg</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.01.MZZZZZZZ.jpg</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.01.LZZZZZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2313</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.01.THUMBZZZ.jpg</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.01.MZZZZZZZ.jpg</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.01.LZZZZZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6543</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.01.THUMBZZZ.jpg</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.01.MZZZZZZZ.jpg</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.01.LZZZZZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8680</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.01.THUMBZZZ.jpg</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.01.MZZZZZZZ.jpg</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.01.LZZZZZZZ.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10314</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0.9</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.01.THUMBZZZ.jpg</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.01.MZZZZZZZ.jpg</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.01.LZZZZZZZ.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating            Book-Title Book-Author  \\\n",
       "0   276725  034545104X          0.0  Flesh Tones: A Novel  M. J. Rose   \n",
       "1     2313  034545104X          0.5  Flesh Tones: A Novel  M. J. Rose   \n",
       "2     6543  034545104X          0.0  Flesh Tones: A Novel  M. J. Rose   \n",
       "3     8680  034545104X          0.5  Flesh Tones: A Novel  M. J. Rose   \n",
       "4    10314  034545104X          0.9  Flesh Tones: A Novel  M. J. Rose   \n",
       "\n",
       "  Year-Of-Publication         Publisher  \\\n",
       "0                2002  Ballantine Books   \n",
       "1                2002  Ballantine Books   \n",
       "2                2002  Ballantine Books   \n",
       "3                2002  Ballantine Books   \n",
       "4                2002  Ballantine Books   \n",
       "\n",
       "                                                    Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/034545104X.01.THUMBZZZ.jpg   \n",
       "1  http://images.amazon.com/images/P/034545104X.01.THUMBZZZ.jpg   \n",
       "2  http://images.amazon.com/images/P/034545104X.01.THUMBZZZ.jpg   \n",
       "3  http://images.amazon.com/images/P/034545104X.01.THUMBZZZ.jpg   \n",
       "4  http://images.amazon.com/images/P/034545104X.01.THUMBZZZ.jpg   \n",
       "\n",
       "                                                    Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/034545104X.01.MZZZZZZZ.jpg   \n",
       "1  http://images.amazon.com/images/P/034545104X.01.MZZZZZZZ.jpg   \n",
       "2  http://images.amazon.com/images/P/034545104X.01.MZZZZZZZ.jpg   \n",
       "3  http://images.amazon.com/images/P/034545104X.01.MZZZZZZZ.jpg   \n",
       "4  http://images.amazon.com/images/P/034545104X.01.MZZZZZZZ.jpg   \n",
       "\n",
       "                                                    Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/034545104X.01.LZZZZZZZ.jpg  \n",
       "1  http://images.amazon.com/images/P/034545104X.01.LZZZZZZZ.jpg  \n",
       "2  http://images.amazon.com/images/P/034545104X.01.LZZZZZZZ.jpg  \n",
       "3  http://images.amazon.com/images/P/034545104X.01.LZZZZZZZ.jpg  \n",
       "4  http://images.amazon.com/images/P/034545104X.01.LZZZZZZZ.jpg  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = ratings.merge(books)\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd50b4c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:32:12.406678Z",
     "iopub.status.busy": "2023-07-19T01:32:12.406372Z",
     "iopub.status.idle": "2023-07-19T01:32:12.484371Z",
     "shell.execute_reply": "2023-07-19T01:32:12.483228Z"
    },
    "papermill": {
     "duration": 0.100088,
     "end_time": "2023-07-19T01:32:12.487345",
     "exception": false,
     "start_time": "2023-07-19T01:32:12.387257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2313</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6543</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8680</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10314</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user                 title  rating\n",
       "0  276725  Flesh Tones: A Novel     0.0\n",
       "1    2313  Flesh Tones: A Novel     0.5\n",
       "2    6543  Flesh Tones: A Novel     0.0\n",
       "3    8680  Flesh Tones: A Novel     0.5\n",
       "4   10314  Flesh Tones: A Novel     0.9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_list = ['User-ID', 'Book-Title', 'Book-Rating',]\n",
    "del_list = ratings.columns.drop(keep_list)\n",
    "del_list\n",
    "ratings = ratings.drop(del_list, axis = 1)\n",
    "ratings = ratings[keep_list] # changes the order\n",
    "ratings = ratings.rename(columns={'User-ID': 'user', 'Book-Title': 'title', 'Book-Rating': 'rating'})\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fffcfa4",
   "metadata": {
    "papermill": {
     "duration": 0.018467,
     "end_time": "2023-07-19T01:32:12.526128",
     "exception": false,
     "start_time": "2023-07-19T01:32:12.507661",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Now we've got a table of book titles, ratings and user IDs. Let's make a fastai Dataloaders object\n",
    "The dataloaders object specifies a way of getting a series of mini batches (training and validation) from a dataset. Here our model will be a collaborative filtering model, which is a little different to what we've seen before with image recognition problems. In this case we'll be using the __book rating__ as the label, and the __book-title__ and __user-id__ as the input features. \n",
    "\n",
    "## Embeddings\n",
    "Since there are hundreds of thousands of individual user IDs, and many more book titles, it will be useful to __compress this data__ in some way - __in a way which keeps the relevant information about each user and book__, but doesn't require the model to learn each individual user ID or book title. This is where Embeddings come in handy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c717ac9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:32:12.566513Z",
     "iopub.status.busy": "2023-07-19T01:32:12.566152Z",
     "iopub.status.idle": "2023-07-19T01:32:14.829100Z",
     "shell.execute_reply": "2023-07-19T01:32:14.828098Z"
    },
    "papermill": {
     "duration": 2.285066,
     "end_time": "2023-07-19T01:32:14.831675",
     "exception": false,
     "start_time": "2023-07-19T01:32:12.546609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dls = CollabDataLoaders.from_df(ratings, item_name='title', bs=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfa578a",
   "metadata": {
    "papermill": {
     "duration": 0.019205,
     "end_time": "2023-07-19T01:32:14.870548",
     "exception": false,
     "start_time": "2023-07-19T01:32:14.851343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Now let's make a dataloaders object\n",
    "The dataloaders object gives us a quick way of getting a batch of features and labels from separate training and validation datasets. Below we can see pairings of 16 input features- users with book titles- and the corresponding label for these features, which is the rating the user gave for the book. 16 is the batch size, which I've chosen to be a small number for displaying here - but I'll change it to 64 later and experiment with different batch sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1781d322",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:32:14.909212Z",
     "iopub.status.busy": "2023-07-19T01:32:14.908872Z",
     "iopub.status.idle": "2023-07-19T01:32:15.898569Z",
     "shell.execute_reply": "2023-07-19T01:32:15.897514Z"
    },
    "papermill": {
     "duration": 1.012349,
     "end_time": "2023-07-19T01:32:15.901495",
     "exception": false,
     "start_time": "2023-07-19T01:32:14.889146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 47626, 124992],\n",
       "         [  3209, 208661],\n",
       "         [ 57702,  66456],\n",
       "         [ 53134, 126270],\n",
       "         [ 64848, 162789],\n",
       "         [ 30800, 217912],\n",
       "         [ 39640, 125673],\n",
       "         [ 77900, 174712],\n",
       "         [  3209, 182773],\n",
       "         [ 61918,  76457],\n",
       "         [ 67043,  68012],\n",
       "         [ 21495, 104256],\n",
       "         [ 37042,  49691],\n",
       "         [ 30890, 172413],\n",
       "         [ 37491, 126020],\n",
       "         [ 30687, 108804]]),\n",
       " tensor([[0.0000],\n",
       "         [0.7000],\n",
       "         [0.0000],\n",
       "         [0.8000],\n",
       "         [0.0000],\n",
       "         [0.8000],\n",
       "         [1.0000],\n",
       "         [0.8000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.0000],\n",
       "         [0.3000],\n",
       "         [0.8000]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abe5c22a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:32:15.941282Z",
     "iopub.status.busy": "2023-07-19T01:32:15.940962Z",
     "iopub.status.idle": "2023-07-19T01:32:16.279669Z",
     "shell.execute_reply": "2023-07-19T01:32:16.278600Z"
    },
    "papermill": {
     "duration": 0.361965,
     "end_time": "2023-07-19T01:32:16.282485",
     "exception": false,
     "start_time": "2023-07-19T01:32:15.920520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16488</td>\n",
       "      <td>Breathing Lessons</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123790</td>\n",
       "      <td>Stitch 'N Bitch: The Knitter's Handbook</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>181176</td>\n",
       "      <td>Lightning (Henry Holt Mystery Series)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#na#</td>\n",
       "      <td>Au Bonheur Des Ogres</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37712</td>\n",
       "      <td>The Da Vinci Code</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>61211</td>\n",
       "      <td>The Five People You Meet in Heaven</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>237856</td>\n",
       "      <td>365 Ways to Become a Millionaire: (Without Being Born One)</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#na#</td>\n",
       "      <td>More Hours in My Day</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1733</td>\n",
       "      <td>It'S All In The Game (Harlequin Superromance No. 302)</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>171604</td>\n",
       "      <td>Twilight Ecstasy (Heartlines)</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.valid.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d795343",
   "metadata": {
    "papermill": {
     "duration": 0.019435,
     "end_time": "2023-07-19T01:32:16.321741",
     "exception": false,
     "start_time": "2023-07-19T01:32:16.302306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Take a sample\n",
    "To speed up development and testing We'll work with a random sample of 300,000 users from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8349cdd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:32:16.360929Z",
     "iopub.status.busy": "2023-07-19T01:32:16.360569Z",
     "iopub.status.idle": "2023-07-19T01:32:17.340197Z",
     "shell.execute_reply": "2023-07-19T01:32:17.339235Z"
    },
    "papermill": {
     "duration": 1.00227,
     "end_time": "2023-07-19T01:32:17.342896",
     "exception": false,
     "start_time": "2023-07-19T01:32:16.340626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_of_samples = 300000\n",
    "df=ratings.sample(number_of_samples)\n",
    "dls = CollabDataLoaders.from_df(df, item_name='title', bs=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00314314",
   "metadata": {
    "papermill": {
     "duration": 0.019225,
     "end_time": "2023-07-19T01:32:17.381093",
     "exception": false,
     "start_time": "2023-07-19T01:32:17.361868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Crosstab\n",
    "Here's a crosstab representation of the data. This is how we'll think of the data, though in reality all the model will see is one batch from the dataloaders object at a time. Note that the table is very sparsely populated - this is because most users haven't read many of the books in the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6547c744",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:32:17.422276Z",
     "iopub.status.busy": "2023-07-19T01:32:17.421933Z",
     "iopub.status.idle": "2023-07-19T01:32:17.477911Z",
     "shell.execute_reply": "2023-07-19T01:32:17.476878Z"
    },
    "papermill": {
     "duration": 0.079509,
     "end_time": "2023-07-19T01:32:17.480912",
     "exception": false,
     "start_time": "2023-07-19T01:32:17.401403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>title</th>\n",
       "      <th>A Savior Worth Having</th>\n",
       "      <th>Among men and beasts</th>\n",
       "      <th>Back Roads</th>\n",
       "      <th>Betrayals : Book Four of the Blending (The Blending, Book 4)</th>\n",
       "      <th>Beyond Chaos: One Man's Journey Alongside His Chronically Ill Wife</th>\n",
       "      <th>Big Shoe, Little Shoe</th>\n",
       "      <th>Chameleon</th>\n",
       "      <th>Clans of the Alphane Moon</th>\n",
       "      <th>Cowboy Feng's Space Bar and Grille</th>\n",
       "      <th>Dating Without Novocaine (Red Dress Ink)</th>\n",
       "      <th>...</th>\n",
       "      <th>The Lovely Bones: A Novel</th>\n",
       "      <th>The Magic School Bus Lost in the Solar System (Magic School Bus (Paperback))</th>\n",
       "      <th>The Magician's Nephew (rack) (Narnia)</th>\n",
       "      <th>The Reptile Room (A Series of Unfortunate Events, Book 2)</th>\n",
       "      <th>The Rock Says...</th>\n",
       "      <th>The Street Lawyer</th>\n",
       "      <th>The Wind Done Gone: A Novel</th>\n",
       "      <th>When We Were Orphans (Vintage International (Paperback))</th>\n",
       "      <th>While I Was Gone</th>\n",
       "      <th>Wild Rose of Ruby Canyon</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11630</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11676</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17950</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21659</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "title  A Savior Worth Having  Among men and beasts  Back Roads  \\\n",
       "user                                                             \n",
       "1249                     NaN                   NaN         NaN   \n",
       "11630                    NaN                   NaN         NaN   \n",
       "11676                    NaN                   NaN         NaN   \n",
       "17950                    NaN                   NaN         NaN   \n",
       "21659                    NaN                   NaN         NaN   \n",
       "\n",
       "title  Betrayals : Book Four of the Blending (The Blending, Book 4)  \\\n",
       "user                                                                  \n",
       "1249                                                            NaN   \n",
       "11630                                                           NaN   \n",
       "11676                                                           NaN   \n",
       "17950                                                           NaN   \n",
       "21659                                                           NaN   \n",
       "\n",
       "title  Beyond Chaos: One Man's Journey Alongside His Chronically Ill Wife  \\\n",
       "user                                                                        \n",
       "1249                                                                  NaN   \n",
       "11630                                                                 NaN   \n",
       "11676                                                                 NaN   \n",
       "17950                                                                 NaN   \n",
       "21659                                                                 NaN   \n",
       "\n",
       "title  Big Shoe, Little Shoe  Chameleon  Clans of the Alphane Moon  \\\n",
       "user                                                                 \n",
       "1249                     NaN        NaN                        NaN   \n",
       "11630                    NaN        NaN                        0.0   \n",
       "11676                    NaN        NaN                        NaN   \n",
       "17950                    NaN        NaN                        NaN   \n",
       "21659                    NaN        NaN                        NaN   \n",
       "\n",
       "title  Cowboy Feng's Space Bar and Grille  \\\n",
       "user                                        \n",
       "1249                                  NaN   \n",
       "11630                                 NaN   \n",
       "11676                                 NaN   \n",
       "17950                                 NaN   \n",
       "21659                                 NaN   \n",
       "\n",
       "title  Dating Without Novocaine (Red Dress Ink)  ...  \\\n",
       "user                                             ...   \n",
       "1249                                        NaN  ...   \n",
       "11630                                       NaN  ...   \n",
       "11676                                       NaN  ...   \n",
       "17950                                       NaN  ...   \n",
       "21659                                       NaN  ...   \n",
       "\n",
       "title  The Lovely Bones: A Novel  \\\n",
       "user                               \n",
       "1249                         NaN   \n",
       "11630                        NaN   \n",
       "11676                        NaN   \n",
       "17950                        NaN   \n",
       "21659                        NaN   \n",
       "\n",
       "title  The Magic School Bus Lost in the Solar System (Magic School Bus (Paperback))  \\\n",
       "user                                                                                  \n",
       "1249                                                                            NaN   \n",
       "11630                                                                           NaN   \n",
       "11676                                                                           NaN   \n",
       "17950                                                                           NaN   \n",
       "21659                                                                           NaN   \n",
       "\n",
       "title  The Magician's Nephew (rack) (Narnia)  \\\n",
       "user                                           \n",
       "1249                                     NaN   \n",
       "11630                                    NaN   \n",
       "11676                                    NaN   \n",
       "17950                                    NaN   \n",
       "21659                                    NaN   \n",
       "\n",
       "title  The Reptile Room (A Series of Unfortunate Events, Book 2)  \\\n",
       "user                                                               \n",
       "1249                                                         NaN   \n",
       "11630                                                        NaN   \n",
       "11676                                                        NaN   \n",
       "17950                                                        NaN   \n",
       "21659                                                        NaN   \n",
       "\n",
       "title  The Rock Says...  The Street Lawyer  The Wind Done Gone: A Novel  \\\n",
       "user                                                                      \n",
       "1249                NaN                NaN                          NaN   \n",
       "11630               NaN                NaN                          NaN   \n",
       "11676               NaN                NaN                          NaN   \n",
       "17950               NaN                NaN                          NaN   \n",
       "21659               NaN                NaN                          NaN   \n",
       "\n",
       "title  When We Were Orphans (Vintage International (Paperback))  \\\n",
       "user                                                              \n",
       "1249                                                        NaN   \n",
       "11630                                                       NaN   \n",
       "11676                                                       NaN   \n",
       "17950                                                       NaN   \n",
       "21659                                                       NaN   \n",
       "\n",
       "title  While I Was Gone  Wild Rose of Ruby Canyon  \n",
       "user                                               \n",
       "1249                NaN                       NaN  \n",
       "11630               NaN                       NaN  \n",
       "11676               NaN                       0.8  \n",
       "17950               NaN                       NaN  \n",
       "21659               0.0                       NaN  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = df.sample(50)\n",
    "pd.crosstab(sdf.user, sdf.title, values=sdf.rating, aggfunc='max').head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c269a49d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-10T20:09:55.573213Z",
     "iopub.status.busy": "2023-06-10T20:09:55.572815Z",
     "iopub.status.idle": "2023-06-10T20:09:55.580468Z",
     "shell.execute_reply": "2023-06-10T20:09:55.579111Z",
     "shell.execute_reply.started": "2023-06-10T20:09:55.573181Z"
    },
    "papermill": {
     "duration": 0.019034,
     "end_time": "2023-07-19T01:32:17.520921",
     "exception": false,
     "start_time": "2023-07-19T01:32:17.501887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Creating an embedding matrix\n",
    "\n",
    "Since we have a very large number of categorical input features, we need some way of compressing this information. We'll create two __matrices of latent factors__  -one for the users and one for the books. Each of these matrices will have a vector containing factors,  where each factor represents something about books, or something about users. \n",
    "\n",
    "For example - we'll begin by creating 5 x 3058 matrix for the users, and a 5 * 4473 matrix for the books. conceptually you can imagine these slotting in to the right of the __user__ column, and below the __title__ colum in such a way that each book, and each user, will have its own unique set of 5 factors. These factors will initially be random numbers, but as the model trains, they will start to encode something meaningful about users' preferences, and something about books' qualities. We won't decide what these factors mean; that will be learned by the model during training. \n",
    "\n",
    "Let's go ahead and make these matrices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c86721b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:32:17.561161Z",
     "iopub.status.busy": "2023-07-19T01:32:17.560802Z",
     "iopub.status.idle": "2023-07-19T01:32:17.579776Z",
     "shell.execute_reply": "2023-07-19T01:32:17.578825Z"
    },
    "papermill": {
     "duration": 0.04135,
     "end_time": "2023-07-19T01:32:17.581853",
     "exception": false,
     "start_time": "2023-07-19T01:32:17.540503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40705, 5]), torch.Size([116160, 5]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users = len(dls.classes['user'])\n",
    "n_titles = len(dls.classes['title'])\n",
    "n_factors = 5\n",
    "\n",
    "user_factors = torch.randn(n_users, n_factors)\n",
    "title_factors = torch.randn(n_titles, n_factors)\n",
    "user_factors.size(), title_factors.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3482b858",
   "metadata": {
    "papermill": {
     "duration": 0.019026,
     "end_time": "2023-07-19T01:32:17.621405",
     "exception": false,
     "start_time": "2023-07-19T01:32:17.602379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Looking at the features\n",
    "\n",
    "To make a forward pass through the model, we'll take the __dot product__ of some user factors with some title factors. If the vectors are similar, then it means that the user's tastes are matched to the book's qualities. Let's take a look at this more closely:\n",
    "\n",
    "Suppose user A has the factors (0, 1, 0.5, 0, -1) , \n",
    "\n",
    "and book N has the factors    (0, 1, 0.6, 1, -1)\n",
    "\n",
    "Since most of these factors are similar, except at index 3, we'll get an output which is more positive, indicating that the book is a good match for the user. If the factors were all opposite to one-another, we'd get a more negative output; perhaps not such a good match. The factors in this case might encode for something like this: \n",
    "\n",
    "- 'written in english'\n",
    "\n",
    "- 'short book', \n",
    "\n",
    "- 'written in the past 20 years', \n",
    "\n",
    "- 'written by terry pratchett', \n",
    "\n",
    "- 'contains dragons'\n",
    "\n",
    "But the factors are learned automatically as the model trains.\n",
    "\n",
    "# Dot Product, Vectors and Scalars\n",
    "https://www.mathsisfun.com/algebra/vectors-dot-product.html\n",
    "On this site you can get a quick refresher on vectors, scalars, and dot procucts. \n",
    "\n",
    "In short, if you imagine two vectors on a plane, the dot product returns a scalar value describing how much these vectors overlap, or more accurately, what's the magnitude of the component shared by both the vectors. \n",
    "\n",
    "Let's try this out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70f087cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:32:17.662683Z",
     "iopub.status.busy": "2023-07-19T01:32:17.661783Z",
     "iopub.status.idle": "2023-07-19T01:32:17.667003Z",
     "shell.execute_reply": "2023-07-19T01:32:17.666138Z"
    },
    "papermill": {
     "duration": 0.027723,
     "end_time": "2023-07-19T01:32:17.669032",
     "exception": false,
     "start_time": "2023-07-19T01:32:17.641309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_a = torch.tensor([1, 0, 0.5])\n",
    "vector_b = torch.tensor([1, 1, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f793b411",
   "metadata": {
    "papermill": {
     "duration": 0.019196,
     "end_time": "2023-07-19T01:32:17.707425",
     "exception": false,
     "start_time": "2023-07-19T01:32:17.688229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The __dot product__ is just the sum of the products of all the features like so: \n",
    "\n",
    "`a1b1 + a2b2 + a3b3`. \n",
    "\n",
    "So the dot product of these vectors would be \n",
    "\n",
    "\n",
    "`1 + 0 + 0.05 = 1.05`\n",
    "\n",
    "### This is just the sum of an elementwise multiplication in python, which is also identical to a matrix multiplaction of two vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d42d952",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:32:17.748195Z",
     "iopub.status.busy": "2023-07-19T01:32:17.747249Z",
     "iopub.status.idle": "2023-07-19T01:32:17.755876Z",
     "shell.execute_reply": "2023-07-19T01:32:17.754872Z"
    },
    "papermill": {
     "duration": 0.031127,
     "end_time": "2023-07-19T01:32:17.757934",
     "exception": false,
     "start_time": "2023-07-19T01:32:17.726807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0500)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum of elementwise multiplication\n",
    "(vector_a*vector_b).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa55a5bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:32:17.799486Z",
     "iopub.status.busy": "2023-07-19T01:32:17.798886Z",
     "iopub.status.idle": "2023-07-19T01:32:17.836208Z",
     "shell.execute_reply": "2023-07-19T01:32:17.835123Z"
    },
    "papermill": {
     "duration": 0.060782,
     "end_time": "2023-07-19T01:32:17.838595",
     "exception": false,
     "start_time": "2023-07-19T01:32:17.777813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0500)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix multiply\n",
    "vector_a@vector_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc34bfb1",
   "metadata": {
    "papermill": {
     "duration": 0.019886,
     "end_time": "2023-07-19T01:32:17.879025",
     "exception": false,
     "start_time": "2023-07-19T01:32:17.859139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# What's an embedding layer?\n",
    "\n",
    "\n",
    "The Embedding class here creates an embedding matrix, just like we did above. It also provides a way of indexing into the matrix to get the vector at a specific index. \n",
    "\n",
    "The input x in this case is one batch of user IDs and  book titles, with the shape bs x 2. When we pass the input to the embedding layer, we'll get back the vectors containing the factors for that batch of inputs. \n",
    "\n",
    "The matrix multiply way of doing this is to one-hot encode the input indices in a one dimensional matrix (or 2d vector, however you want to think of it), then do a matrix multiply of this one hot encoded vector with the embedding matrix. The result would be a 16x5 matrix of feature vectors- one for each of the inputs in the minibatch. An embedding layer provides a way to get the embedding vectors out of the embedding matrix using indexes, in a way which looks just like matrix multiplication, without the need to build the one-hot encoded matrix with all those redundant zeros. \n",
    "\n",
    "__There may be some relation between an embedding for a particular book, and an embedding for a particular user, which correlates with the rating that user gave to that book. When we train this model, we're trying to learn the set of parameters for the embeddings for each book and user, such that the dot product of the book embeddings and the user embeddings is close to the actual ratings a user gave for a particular book__.\n",
    "\n",
    "Our model's forward method needs to make rating predictions by doing an elementwise multiplication of the user embedding and the book embedding, then sum over this to predict an overall rating. This predicted rating will be compared with the actual rating the user gave the book, then the initially random weights in the embedding matrix will be updated using stochastic gradient descent to create a better embedding. \n",
    "\n",
    "Through this process the embedding will come to represent some real world features about the data, which relate to the ratings which people gave to books. These features might not be named or explicitly stated by the user, but rather they'll be discovered by the network as its parameters automatically adjust to minimise the output of the loss function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4404ea2d",
   "metadata": {
    "papermill": {
     "duration": 0.01936,
     "end_time": "2023-07-19T01:32:17.918316",
     "exception": false,
     "start_time": "2023-07-19T01:32:17.898956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Making a PyTorch dot product model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c77d9f50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:32:17.959366Z",
     "iopub.status.busy": "2023-07-19T01:32:17.959024Z",
     "iopub.status.idle": "2023-07-19T01:32:17.965448Z",
     "shell.execute_reply": "2023-07-19T01:32:17.964452Z"
    },
    "papermill": {
     "duration": 0.029214,
     "end_time": "2023-07-19T01:32:17.967441",
     "exception": false,
     "start_time": "2023-07-19T01:32:17.938227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DotProduct(Module):\n",
    "    def __init__(self, n_users, n_titles, n_factors):\n",
    "        self.user_factors = Embedding(n_users, n_factors)\n",
    "        self.title_factors = Embedding(n_titles, n_factors)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors(x[:,0])\n",
    "        titles = self.title_factors(x[:,1])\n",
    "        return (users*titles).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5f2aef5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:32:18.008456Z",
     "iopub.status.busy": "2023-07-19T01:32:18.007612Z",
     "iopub.status.idle": "2023-07-19T01:32:18.267872Z",
     "shell.execute_reply": "2023-07-19T01:32:18.266739Z"
    },
    "papermill": {
     "duration": 0.284084,
     "end_time": "2023-07-19T01:32:18.271115",
     "exception": false,
     "start_time": "2023-07-19T01:32:17.987031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 2]), torch.Size([64, 1]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = dls.one_batch()\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8a0c6e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:32:18.315300Z",
     "iopub.status.busy": "2023-07-19T01:32:18.314658Z",
     "iopub.status.idle": "2023-07-19T01:32:18.495233Z",
     "shell.execute_reply": "2023-07-19T01:32:18.494283Z"
    },
    "papermill": {
     "duration": 0.204372,
     "end_time": "2023-07-19T01:32:18.497781",
     "exception": false,
     "start_time": "2023-07-19T01:32:18.293409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = DotProduct(n_users, n_titles, n_factors=50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa8f349a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:32:18.539366Z",
     "iopub.status.busy": "2023-07-19T01:32:18.539026Z",
     "iopub.status.idle": "2023-07-19T01:34:40.218923Z",
     "shell.execute_reply": "2023-07-19T01:34:40.217874Z"
    },
    "papermill": {
     "duration": 141.703668,
     "end_time": "2023-07-19T01:34:40.221606",
     "exception": false,
     "start_time": "2023-07-19T01:32:18.517938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.230327</td>\n",
       "      <td>0.225140</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.182791</td>\n",
       "      <td>0.224386</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.089434</td>\n",
       "      <td>0.226122</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.046783</td>\n",
       "      <td>0.222329</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.024537</td>\n",
       "      <td>0.222625</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, 5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23e4c63",
   "metadata": {
    "papermill": {
     "duration": 0.019855,
     "end_time": "2023-07-19T01:34:40.264810",
     "exception": false,
     "start_time": "2023-07-19T01:34:40.244955",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Making the training process more efficient\n",
    "### Training on the entire dataset took 3 mins per epoch.\n",
    "When I first ran this model it took 15 mins for 5 epochs. \n",
    "The model was still converging after 5 epochs but this is too slow for experimentation - we should find a sample size which allows some convergence, but which we don't have to wait forever to train. \n",
    "\n",
    "For the next run, I took a random sample of 300,000 users from the database. This reduced the training time but reduced convergence - the loss measured on the validation set remained high. We need a way of reducing the size of the dataset but retaining most of the data. \n",
    "\n",
    "## Sample only popular books and users with lots of entries. \n",
    "Deliberately selecting from the most read titles, and the most active readers could be a way of getting the information density up a little. This is definitely a design decision which should be scrutinized, since it biases the system towards more popular items, but it could be a good way to jumpstart training. \n",
    "\n",
    "Plus it doesn't make a lot of sense to be training a collaborative filtering model on users who have read only one book: there wouldn't be any second item to lookup and recommend for another user who has read the same book. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9c89046",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:34:40.309025Z",
     "iopub.status.busy": "2023-07-19T01:34:40.308638Z",
     "iopub.status.idle": "2023-07-19T01:34:40.957149Z",
     "shell.execute_reply": "2023-07-19T01:34:40.956146Z"
    },
    "papermill": {
     "duration": 0.673387,
     "end_time": "2023-07-19T01:34:40.959617",
     "exception": false,
     "start_time": "2023-07-19T01:34:40.286230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "book_count = len(set(ratings.title))\n",
    "popular_books = ratings.title.value_counts()[:1000].keys()\n",
    "\n",
    "reader_count = len(set(ratings.user))\n",
    "avid_readers = ratings.user.value_counts()[:1000].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "970a5f11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:34:41.001115Z",
     "iopub.status.busy": "2023-07-19T01:34:41.000781Z",
     "iopub.status.idle": "2023-07-19T01:34:41.006602Z",
     "shell.execute_reply": "2023-07-19T01:34:41.005763Z"
    },
    "papermill": {
     "duration": 0.028793,
     "end_time": "2023-07-19T01:34:41.008597",
     "exception": false,
     "start_time": "2023-07-19T01:34:40.979804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1031136"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc80cbc",
   "metadata": {
    "papermill": {
     "duration": 0.01979,
     "end_time": "2023-07-19T01:34:41.048498",
     "exception": false,
     "start_time": "2023-07-19T01:34:41.028708",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Overwriting the variable __dense_df__ with this new selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "147a3ee0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:34:41.090503Z",
     "iopub.status.busy": "2023-07-19T01:34:41.089012Z",
     "iopub.status.idle": "2023-07-19T01:34:41.168057Z",
     "shell.execute_reply": "2023-07-19T01:34:41.167078Z"
    },
    "papermill": {
     "duration": 0.101917,
     "end_time": "2023-07-19T01:34:41.170114",
     "exception": false,
     "start_time": "2023-07-19T01:34:41.068197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76402\n"
     ]
    }
   ],
   "source": [
    "dense_df = ratings[ratings.title.isin(popular_books)]\n",
    "dense_df = (dense_df[dense_df.user.isin(avid_readers)])\n",
    "print(len(dense_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b81f50",
   "metadata": {
    "papermill": {
     "duration": 0.019711,
     "end_time": "2023-07-19T01:34:41.210214",
     "exception": false,
     "start_time": "2023-07-19T01:34:41.190503",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we've got the number of samples in the database down to 76402, and it only contains the top 1000 readers and the top 1000 books. \n",
    "\n",
    "##  Make a new dataloaders object to draw training and validation samples from this new dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a645c1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:34:41.253534Z",
     "iopub.status.busy": "2023-07-19T01:34:41.251992Z",
     "iopub.status.idle": "2023-07-19T01:34:41.319498Z",
     "shell.execute_reply": "2023-07-19T01:34:41.318535Z"
    },
    "papermill": {
     "duration": 0.091743,
     "end_time": "2023-07-19T01:34:41.322261",
     "exception": false,
     "start_time": "2023-07-19T01:34:41.230518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dense_dls = CollabDataLoaders.from_df(dense_df, item_name='title', bs=64)\n",
    "n_users = len(dense_dls.classes['user'])\n",
    "n_titles = len(dense_dls.classes['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9e8fbbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:34:41.365147Z",
     "iopub.status.busy": "2023-07-19T01:34:41.364823Z",
     "iopub.status.idle": "2023-07-19T01:34:41.372582Z",
     "shell.execute_reply": "2023-07-19T01:34:41.371742Z"
    },
    "papermill": {
     "duration": 0.031425,
     "end_time": "2023-07-19T01:34:41.374558",
     "exception": false,
     "start_time": "2023-07-19T01:34:41.343133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = DotProduct(n_users, n_titles, n_factors=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15b9a6",
   "metadata": {
    "papermill": {
     "duration": 0.019597,
     "end_time": "2023-07-19T01:34:41.414614",
     "exception": false,
     "start_time": "2023-07-19T01:34:41.395017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Let's see how the model trains now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3b6b678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:34:41.456866Z",
     "iopub.status.busy": "2023-07-19T01:34:41.456006Z",
     "iopub.status.idle": "2023-07-19T01:35:14.554684Z",
     "shell.execute_reply": "2023-07-19T01:35:14.553737Z"
    },
    "papermill": {
     "duration": 33.122428,
     "end_time": "2023-07-19T01:35:14.556754",
     "exception": false,
     "start_time": "2023-07-19T01:34:41.434326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.175163</td>\n",
       "      <td>0.170583</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.129468</td>\n",
       "      <td>0.121618</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.106404</td>\n",
       "      <td>0.113181</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.098074</td>\n",
       "      <td>0.111734</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.094152</td>\n",
       "      <td>0.111598</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dense_dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5b2b50",
   "metadata": {
    "papermill": {
     "duration": 0.021107,
     "end_time": "2023-07-19T01:35:14.600247",
     "exception": false,
     "start_time": "2023-07-19T01:35:14.579140",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Great - the training only takes 5s per epoch, and we're still seeing convergence after 5 epochs. Let's try to improve from here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddcb67c",
   "metadata": {
    "papermill": {
     "duration": 0.021033,
     "end_time": "2023-07-19T01:35:14.642210",
     "exception": false,
     "start_time": "2023-07-19T01:35:14.621177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Adding intentional Bias\n",
    "So far our model only takes the dot procuct of two vectors then adds up these contributions. To improve the model we should add bias. This will allow us to represent the overall bias of a particular book or user. For example, a book might be extremely short and extremely sci-fi, but also be generally terrible. Even for a reader who also loves short sci-fi books, if the book is generally terrible they probably won't enjoy it. Conversely there might be a book which is very sci-fi but also so good that even non-sci-fi fans enjoy it. We can represent this overall bias of the book by adding or subtracting a scalar to our embedding vector after the elementwise multiplication operation. \n",
    "\n",
    "The bias in for the user embedding factors lets us represent users who on average, give a higher or lower rating than other users across the board. \n",
    "\n",
    "Let's give this a go below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06f915f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:35:14.685126Z",
     "iopub.status.busy": "2023-07-19T01:35:14.684746Z",
     "iopub.status.idle": "2023-07-19T01:35:14.692386Z",
     "shell.execute_reply": "2023-07-19T01:35:14.691470Z"
    },
    "papermill": {
     "duration": 0.031495,
     "end_time": "2023-07-19T01:35:14.694413",
     "exception": false,
     "start_time": "2023-07-19T01:35:14.662918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DotProductBias(Module):\n",
    "    def __init__(self, n_users, n_titles, n_factors):\n",
    "        self.user_factors = Embedding(n_users, n_factors)\n",
    "        self.user_bias = Embedding(n_users, 1)\n",
    "        self.title_factors = Embedding(n_titles, n_factors)\n",
    "        self.title_bias = Embedding(n_titles, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors(x[:,0])\n",
    "        titles = self.title_factors(x[:,1])\n",
    "        result = (users*titles).sum(dim=1, keepdim=True)\n",
    "        result += self.user_bias(x[:,0]) + self.title_bias(x[:,1])\n",
    "        return(result) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d42541",
   "metadata": {
    "papermill": {
     "duration": 0.020291,
     "end_time": "2023-07-19T01:35:14.735463",
     "exception": false,
     "start_time": "2023-07-19T01:35:14.715172",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we're just adding another embedding to represent the bias for each user and each book. This scalar value is added to the prediction for a user and book combination. \n",
    "\n",
    "Initially I added added a sigmoid to the output to keep the predictions between 0 and 1.1 Using an upper limit of 1.1 allows prediction of the number 1, which would be impossible to achieve with sigmoid otherwise, since the [sigmoid function](https://en.wikipedia.org/wiki/Sigmoid_function) scales all inputs from -inf to inf to lie between 0 and 1.\n",
    "\n",
    "In practice what happened was that all the predicted ratings were between ~0.4 and ~0.5. Removing the sigmoid on the outputs fixed this and all predicted ratings now fall between 0 and 1, perhaps because I've pre-scaled the ratings to lie within this range. \n",
    "\n",
    "### Weight decay\n",
    "__L2_Regularization__ also called weight decay, is also used here. L2 regularization penalizes large weights in the model by adding to the loss function the sum of all the weights squared. This helps reduce overfitting by reducing the chance of any individual weight becoming very large. This will slow down the training of the model, but it will also produce a model which generalizes better - the model will find general patterns rather than producing an overly complex and overfit function which only represents items in the training set. \n",
    "\n",
    "I have left "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7283143",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:35:14.778778Z",
     "iopub.status.busy": "2023-07-19T01:35:14.778423Z",
     "iopub.status.idle": "2023-07-19T01:35:54.624583Z",
     "shell.execute_reply": "2023-07-19T01:35:54.623478Z"
    },
    "papermill": {
     "duration": 39.871403,
     "end_time": "2023-07-19T01:35:54.627480",
     "exception": false,
     "start_time": "2023-07-19T01:35:14.756077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.139426</td>\n",
       "      <td>0.142063</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.120957</td>\n",
       "      <td>0.115809</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.099875</td>\n",
       "      <td>0.111417</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.089681</td>\n",
       "      <td>0.110612</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.084803</td>\n",
       "      <td>0.110506</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DotProductBias(n_users, n_titles, n_factors=50)\n",
    "learn = Learner(dense_dls, model, loss_func=MSELossFlat()).to_fp16()\n",
    "learn.fit_one_cycle(5, 1e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c0891c",
   "metadata": {
    "papermill": {
     "duration": 0.021099,
     "end_time": "2023-07-19T01:35:54.670299",
     "exception": false,
     "start_time": "2023-07-19T01:35:54.649200",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we have the model trained, we can get predictions for any pairings of users an books. The model outputs will be the rating which the model predicts for that user - book combo. Here's a demonstration which uses one batch of data, so it's just a random pairing of users with books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3c4ea7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:35:54.714803Z",
     "iopub.status.busy": "2023-07-19T01:35:54.714451Z",
     "iopub.status.idle": "2023-07-19T01:35:54.782883Z",
     "shell.execute_reply": "2023-07-19T01:35:54.781845Z"
    },
    "papermill": {
     "duration": 0.092911,
     "end_time": "2023-07-19T01:35:54.785385",
     "exception": false,
     "start_time": "2023-07-19T01:35:54.692474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch = dense_dls.one_batch()[0].to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1c04fb",
   "metadata": {
    "papermill": {
     "duration": 0.020887,
     "end_time": "2023-07-19T01:35:54.829032",
     "exception": false,
     "start_time": "2023-07-19T01:35:54.808145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`get_device` to check that the tensor is on the GPU (-1 = cpum 0=cuda:0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e626064",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:35:54.872903Z",
     "iopub.status.busy": "2023-07-19T01:35:54.872563Z",
     "iopub.status.idle": "2023-07-19T01:35:54.878822Z",
     "shell.execute_reply": "2023-07-19T01:35:54.877829Z"
    },
    "papermill": {
     "duration": 0.031803,
     "end_time": "2023-07-19T01:35:54.881546",
     "exception": false,
     "start_time": "2023-07-19T01:35:54.849743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ca6469",
   "metadata": {
    "papermill": {
     "duration": 0.020944,
     "end_time": "2023-07-19T01:35:54.923411",
     "exception": false,
     "start_time": "2023-07-19T01:35:54.902467",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "passing a batch of inputs (user/title pairs) gives us an output of predictions for that pairing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39d07da0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:35:54.967297Z",
     "iopub.status.busy": "2023-07-19T01:35:54.966471Z",
     "iopub.status.idle": "2023-07-19T01:35:54.991413Z",
     "shell.execute_reply": "2023-07-19T01:35:54.990389Z"
    },
    "papermill": {
     "duration": 0.049225,
     "end_time": "2023-07-19T01:35:54.993570",
     "exception": false,
     "start_time": "2023-07-19T01:35:54.944345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0823],\n",
       "        [ 0.1963],\n",
       "        [ 0.1214],\n",
       "        [ 0.1322],\n",
       "        [ 0.0816],\n",
       "        [ 0.2963],\n",
       "        [ 0.0160],\n",
       "        [ 0.2217],\n",
       "        [ 0.0436],\n",
       "        [-0.0102]], device='cuda:0', grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd263f65",
   "metadata": {
    "papermill": {
     "duration": 0.020767,
     "end_time": "2023-07-19T01:35:55.035553",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.014786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# looking at the factors for a batch of users\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dd6850",
   "metadata": {
    "papermill": {
     "duration": 0.020559,
     "end_time": "2023-07-19T01:35:55.076687",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.056128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here we can see the indices of a batch of users. Each one of these users has a corresponding set of factors which are accessed by passing these indices to the Embedding instance called `user_factors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f41a2102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:35:55.120193Z",
     "iopub.status.busy": "2023-07-19T01:35:55.119332Z",
     "iopub.status.idle": "2023-07-19T01:35:55.127401Z",
     "shell.execute_reply": "2023-07-19T01:35:55.126397Z"
    },
    "papermill": {
     "duration": 0.032082,
     "end_time": "2023-07-19T01:35:55.129374",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.097292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([748,  32, 929,   9, 481, 864, 243,  19, 357, 434, 564, 699, 361, 435,\n",
       "        326, 570, 497, 296, 659, 706, 722, 658,  64, 875, 324, 589,  73, 226,\n",
       "        660, 351, 861, 120, 703, 708, 662,  85,  49, 694, 297,  39,  83, 246,\n",
       "        657, 910, 782, 194, 174,  96, 265, 819, 140, 956, 804, 896, 805, 601,\n",
       "        697, 535, 256, 584, 984, 243, 489, 785], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10213fe",
   "metadata": {
    "papermill": {
     "duration": 0.020624,
     "end_time": "2023-07-19T01:35:55.171289",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.150665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Thinking about latent factors as components of a vector in an n-dimensional feature space\n",
    "Here are the factors for each of the users in the batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7484d86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:35:55.215287Z",
     "iopub.status.busy": "2023-07-19T01:35:55.214383Z",
     "iopub.status.idle": "2023-07-19T01:35:55.228629Z",
     "shell.execute_reply": "2023-07-19T01:35:55.227658Z"
    },
    "papermill": {
     "duration": 0.038375,
     "end_time": "2023-07-19T01:35:55.230672",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.192297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0817, -0.0264,  0.0331,  ..., -0.0489,  0.0411, -0.0605],\n",
       "        [ 0.2433,  0.1127,  0.0474,  ..., -0.0423, -0.0127,  0.0787],\n",
       "        [ 0.0681, -0.0004, -0.0345,  ..., -0.0058, -0.0629, -0.0205],\n",
       "        ...,\n",
       "        [-0.0815,  0.0103, -0.0141,  ...,  0.0457,  0.0288,  0.0169],\n",
       "        [-0.0230,  0.0015, -0.0673,  ..., -0.0892,  0.0012, -0.0144],\n",
       "        [-0.0735, -0.1434, -0.0621,  ...,  0.0003,  0.0648,  0.1412]],\n",
       "       device='cuda:0', grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.user_factors(batch[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c08129f",
   "metadata": {
    "papermill": {
     "duration": 0.02111,
     "end_time": "2023-07-19T01:35:55.273303",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.252193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Each of these numbers represents a learned latent factor for that user. The latent factors can can be thought of as the contribution / component to a vector in n-dimensional space, where each number is a different axis's contribution. The factors are all orthoganal to oneanother. They can represent things like taste, genre, age etc. \n",
    "\n",
    "\n",
    "For example: if user A has 3 latent factors x, y, z, and these have values 1, 0.2, -0.9, then we can imagine a vector in 3d space which extends along the x dimension by 1, along y by 0.2, and extends negatively along the z dimension by 1.\n",
    "\n",
    "Another user, or book title, might point in a very similar direction. This would mean that their factors overlap a lot and tend not to cancel out. \n",
    "\n",
    "Each of these dimensions could code for something like 'enjoys horror books', 'enjoys shorter books', younger.\n",
    "\n",
    "If there was another user who's factors were -1, 0.2, 1, we might say that they had the opposite taste for horror stories, that they have the same liking for shorter books, and that they are older. \n",
    "\n",
    "The latent factors encode for real world meaning, but the factors themselves aren't chosen by the engineer when setting up the neural network - rather they emerge from the relationships between books, users and ratings as the model trains. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f45b42",
   "metadata": {
    "papermill": {
     "duration": 0.021762,
     "end_time": "2023-07-19T01:35:55.316534",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.294772",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Using the trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf3f7ec",
   "metadata": {
    "papermill": {
     "duration": 0.021272,
     "end_time": "2023-07-19T01:35:55.358815",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.337543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Finding the books with the highest bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434d2cae",
   "metadata": {
    "papermill": {
     "duration": 0.021393,
     "end_time": "2023-07-19T01:35:55.401331",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.379938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here's a list of books with a high bias: they end up having a higher rating across the board, despite the specific features which were learned to describe the books. Intuitively this means that they're high quality - since they get consistently high ratings despite their genre and the users' tastes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99de9923",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:35:55.446136Z",
     "iopub.status.busy": "2023-07-19T01:35:55.445195Z",
     "iopub.status.idle": "2023-07-19T01:35:55.460663Z",
     "shell.execute_reply": "2023-07-19T01:35:55.459657Z"
    },
    "papermill": {
     "duration": 0.03968,
     "end_time": "2023-07-19T01:35:55.462796",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.423116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Harry Potter and the Prisoner of Azkaban (Book 3)',\n",
       " \"Harry Potter and the Sorcerer's Stone (Book 1)\",\n",
       " 'Harry Potter and the Chamber of Secrets (Book 2)',\n",
       " 'To Kill a Mockingbird',\n",
       " 'Harry Potter and the Order of the Phoenix (Book 5)',\n",
       " 'The Secret Garden',\n",
       " 'A Wrinkle in Time',\n",
       " \"Harry Potter and the Sorcerer's Stone (Harry Potter (Paperback))\",\n",
       " 'Harry Potter and the Goblet of Fire (Book 4)',\n",
       " 'The Fellowship of the Ring (The Lord of the Rings, Part 1)',\n",
       " 'The Little Prince',\n",
       " 'Fahrenheit 451',\n",
       " \"Where the Heart Is (Oprah's Book Club (Paperback))\",\n",
       " 'Lord of the Flies',\n",
       " 'The Lovely Bones: A Novel',\n",
       " 'Anne Frank: The Diary of a Young Girl',\n",
       " 'The Color Purple',\n",
       " \"The Handmaid's Tale\",\n",
       " 'One for the Money (A Stephanie Plum Novel)',\n",
       " 'The Da Vinci Code']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_bias = learn.model.title_bias.weight.squeeze()\n",
    "idxs = books_bias.argsort(descending=True)[:20]\n",
    "[dense_dls.classes['title'][i] for i in idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb50b01b",
   "metadata": {
    "papermill": {
     "duration": 0.021544,
     "end_time": "2023-07-19T01:35:55.505884",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.484340",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Making recommendations for a single user. \n",
    "We know how to get rating predictions for a single batch: take the dot product of the user factors and title factors for each user/title pariring in the batch. To get predictions for a single user, we'd just need to replace all the user id's with the id for that single user. Let's try this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7be4fa",
   "metadata": {
    "papermill": {
     "duration": 0.020925,
     "end_time": "2023-07-19T01:35:55.548355",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.527430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we have a trained model, to make a recommendation we need to do 2 things: \n",
    "\n",
    "1. Find out which books the user has read already. This is just so that we're not recommending books they've already read. \n",
    "\n",
    "2. Create a tensor of tuples which contain user IDs and book titles. These will be passed to the `DotProductBias` `forward()` method - which takes the dot product of a user-id book-title combination. We need to make the user IDs all the same (11676), and calculate these dot products for every book the user hasn't yet read. Once this calculation is performed, we'll have a prediction of what rating this user might give if they were to read these books. Based on these predictions we can recommend the books which get the highest predicted rating. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce1e3f1",
   "metadata": {
    "papermill": {
     "duration": 0.021356,
     "end_time": "2023-07-19T01:35:55.591201",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.569845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's take a look at the user who has read the most books: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "529ab86d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:35:55.636293Z",
     "iopub.status.busy": "2023-07-19T01:35:55.635938Z",
     "iopub.status.idle": "2023-07-19T01:35:55.646225Z",
     "shell.execute_reply": "2023-07-19T01:35:55.645202Z"
    },
    "papermill": {
     "duration": 0.035063,
     "end_time": "2023-07-19T01:35:55.648307",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.613244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 11676,  35859,  76352,  16795, 153662, 102967, 238120,  23768,\n",
       "            230522,  55492,\n",
       "            ...\n",
       "             69808,   4385, 168464, 164465, 227250,  35433, 241198, 173632,\n",
       "            133868,  72352],\n",
       "           dtype='int64', length=997)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_df.user.value_counts()[:1000].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1991fa9d",
   "metadata": {
    "papermill": {
     "duration": 0.024448,
     "end_time": "2023-07-19T01:35:55.694720",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.670272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "user __11676__\n",
    "\n",
    "This is the ID of the user we're trying to recommend books for. \n",
    "\n",
    "We made an embedding using a subset of the 1000 top users - so we need a way to find which index this ID is at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4e8bbff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:35:55.738845Z",
     "iopub.status.busy": "2023-07-19T01:35:55.738505Z",
     "iopub.status.idle": "2023-07-19T01:35:55.745505Z",
     "shell.execute_reply": "2023-07-19T01:35:55.744651Z"
    },
    "papermill": {
     "duration": 0.031496,
     "end_time": "2023-07-19T01:35:55.747575",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.716079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_index(cat, dataloader):\n",
    "    'get the index of a category from a dataloader'\n",
    "    for i, j in enumerate(dataloader):\n",
    "        if j == cat:\n",
    "            return i\n",
    "        \n",
    "get_index(11676, dense_dls.classes['user'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece8bcd1",
   "metadata": {
    "papermill": {
     "duration": 0.021439,
     "end_time": "2023-07-19T01:35:55.790580",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.769141",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's confirm that this works by tesing it on a book title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eec8782b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:35:55.835781Z",
     "iopub.status.busy": "2023-07-19T01:35:55.835303Z",
     "iopub.status.idle": "2023-07-19T01:35:55.842371Z",
     "shell.execute_reply": "2023-07-19T01:35:55.841190Z"
    },
    "papermill": {
     "duration": 0.032325,
     "end_time": "2023-07-19T01:35:55.844879",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.812554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_index('The Little Prince', dense_dls.classes['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa64ec23",
   "metadata": {
    "papermill": {
     "duration": 0.021726,
     "end_time": "2023-07-19T01:35:55.889037",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.867311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We're going to check for book recommendations for user 11676, who is at index __32__ in our dense dataloaders object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e29dabc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:35:55.933998Z",
     "iopub.status.busy": "2023-07-19T01:35:55.933637Z",
     "iopub.status.idle": "2023-07-19T01:35:55.948629Z",
     "shell.execute_reply": "2023-07-19T01:35:55.947648Z"
    },
    "papermill": {
     "duration": 0.039655,
     "end_time": "2023-07-19T01:35:55.950599",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.910944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  32,    1],\n",
       "        [  32,    2],\n",
       "        [  32,    3],\n",
       "        ...,\n",
       "        [  32,  998],\n",
       "        [  32,  999],\n",
       "        [  32, 1000]], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_index = 32\n",
    "n_books = len(dense_dls.cats['title'].unique())\n",
    "user_idxs = torch.full((n_books, 1), user_index, dtype=int).cuda()\n",
    "book_idxs = torch.linspace(1, n_books, n_books, dtype=int).unsqueeze(1).cuda()\n",
    "user_books_tensor = torch.cat((user_idxs, book_idxs), -1)\n",
    "user_books_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e87a55",
   "metadata": {
    "papermill": {
     "duration": 0.021459,
     "end_time": "2023-07-19T01:35:55.993827",
     "exception": false,
     "start_time": "2023-07-19T01:35:55.972368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we have a tensor pairing the user at index 32 with each of the book indices from 1 to 1000. Passing this into our model's forward() method will calculate the dot product of this user's latent factors vector with the latent factors for each book in the dataset. This dot product is the rating prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9628da14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:35:56.039132Z",
     "iopub.status.busy": "2023-07-19T01:35:56.038513Z",
     "iopub.status.idle": "2023-07-19T01:35:56.047171Z",
     "shell.execute_reply": "2023-07-19T01:35:56.046231Z"
    },
    "papermill": {
     "duration": 0.033343,
     "end_time": "2023-07-19T01:35:56.049176",
     "exception": false,
     "start_time": "2023-07-19T01:35:56.015833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[307],\n",
       "        [174],\n",
       "        [235],\n",
       "        [485],\n",
       "        [363],\n",
       "        [  1],\n",
       "        [ 41],\n",
       "        [861],\n",
       "        [597],\n",
       "        [125]], device='cuda:0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations = model(user_books_tensor)\n",
    "top_10 = recommendations.argsort(0, descending=True)[:10]\n",
    "top_10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046a2c2a",
   "metadata": {
    "papermill": {
     "duration": 0.021946,
     "end_time": "2023-07-19T01:35:56.093002",
     "exception": false,
     "start_time": "2023-07-19T01:35:56.071056",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we have the indices of the top 10 recommended books for this user. Finally we can look up these top indices in the dataloaders classes to get the titles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3e69807",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:35:56.139940Z",
     "iopub.status.busy": "2023-07-19T01:35:56.139099Z",
     "iopub.status.idle": "2023-07-19T01:35:56.146114Z",
     "shell.execute_reply": "2023-07-19T01:35:56.145185Z"
    },
    "papermill": {
     "duration": 0.032779,
     "end_time": "2023-07-19T01:35:56.148136",
     "exception": false,
     "start_time": "2023-07-19T01:35:56.115357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) ['Harry Potter and the Chamber of Secrets (Book 2)','Crazy for You','Empire Falls','One True Thing','Isle of Dogs','1984','A Widow for One Year','The Secret','Sisterhood of the Traveling Pants','By the Light of the Moon']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_dls.classes['title'][top_10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff6ba2e",
   "metadata": {
    "papermill": {
     "duration": 0.021718,
     "end_time": "2023-07-19T01:35:56.191947",
     "exception": false,
     "start_time": "2023-07-19T01:35:56.170229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's take a look at all the books this user has read, ordered by rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d84fa969",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:35:56.237979Z",
     "iopub.status.busy": "2023-07-19T01:35:56.237636Z",
     "iopub.status.idle": "2023-07-19T01:35:56.254081Z",
     "shell.execute_reply": "2023-07-19T01:35:56.253159Z"
    },
    "papermill": {
     "duration": 0.041934,
     "end_time": "2023-07-19T01:35:56.256248",
     "exception": false,
     "start_time": "2023-07-19T01:35:56.214314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>11676</td>\n",
       "      <td>The Notebook</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>11676</td>\n",
       "      <td>A Painted House</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12730</th>\n",
       "      <td>11676</td>\n",
       "      <td>Harry Potter and the Chamber of Secrets (Book 2)</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13401</th>\n",
       "      <td>11676</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (Harry Potter (Paperback))</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19165</th>\n",
       "      <td>11676</td>\n",
       "      <td>The Sweet Potato Queens' Book of Love</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19881</th>\n",
       "      <td>11676</td>\n",
       "      <td>Dreamcatcher</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20480</th>\n",
       "      <td>11676</td>\n",
       "      <td>Fight Club</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26049</th>\n",
       "      <td>11676</td>\n",
       "      <td>1st to Die: A Novel</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26691</th>\n",
       "      <td>11676</td>\n",
       "      <td>The Hot Zone</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28195</th>\n",
       "      <td>11676</td>\n",
       "      <td>The Girl Who Loved Tom Gordon</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user  \\\n",
       "69     11676   \n",
       "189    11676   \n",
       "12730  11676   \n",
       "13401  11676   \n",
       "19165  11676   \n",
       "19881  11676   \n",
       "20480  11676   \n",
       "26049  11676   \n",
       "26691  11676   \n",
       "28195  11676   \n",
       "\n",
       "                                                                  title  \\\n",
       "69                                                         The Notebook   \n",
       "189                                                     A Painted House   \n",
       "12730                  Harry Potter and the Chamber of Secrets (Book 2)   \n",
       "13401  Harry Potter and the Sorcerer's Stone (Harry Potter (Paperback))   \n",
       "19165                             The Sweet Potato Queens' Book of Love   \n",
       "19881                                                      Dreamcatcher   \n",
       "20480                                                        Fight Club   \n",
       "26049                                               1st to Die: A Novel   \n",
       "26691                                                      The Hot Zone   \n",
       "28195                                     The Girl Who Loved Tom Gordon   \n",
       "\n",
       "       rating  \n",
       "69        1.0  \n",
       "189       1.0  \n",
       "12730     1.0  \n",
       "13401     1.0  \n",
       "19165     1.0  \n",
       "19881     1.0  \n",
       "20480     1.0  \n",
       "26049     1.0  \n",
       "26691     1.0  \n",
       "28195     1.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_df.loc[dense_df.user==11676].loc[dense_df.rating==1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c6f2436",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:35:56.304430Z",
     "iopub.status.busy": "2023-07-19T01:35:56.302936Z",
     "iopub.status.idle": "2023-07-19T01:35:56.311583Z",
     "shell.execute_reply": "2023-07-19T01:35:56.310567Z"
    },
    "papermill": {
     "duration": 0.034183,
     "end_time": "2023-07-19T01:35:56.313616",
     "exception": false,
     "start_time": "2023-07-19T01:35:56.279433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1069, device='cuda:0', grad_fn=<MinBackward1>),\n",
       " tensor(0.9967, device='cuda:0', grad_fn=<MaxBackward1>))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations.min(), recommendations.max()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fa10df",
   "metadata": {
    "papermill": {
     "duration": 0.022524,
     "end_time": "2023-07-19T01:35:56.358414",
     "exception": false,
     "start_time": "2023-07-19T01:35:56.335890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Finding 'book buddies' \n",
    "\n",
    "We can use the same approach to pair users with people they're most similar to - If there are two readers in the model with the same set of latent factors as oneanother, then this means they have very similar tastes in books. I remember the Last.FM music recommendation software had a feature where you could see your 'musical neighbours' and see what music they'd been listening to. This likely uses a similar collaborative filtering system.\n",
    "\n",
    "To find two similar readers, we could use the following approach:\n",
    "\n",
    "1. pick a user\n",
    "2. apply the same process as above but instead of calculating the dot product of this user with every book, calculate the dot product of the user with every other user. If their latent factors are similar they're likely to have similar tastes in books. \n",
    "\n",
    "Let's give this  a go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5a74ae2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T01:35:56.405564Z",
     "iopub.status.busy": "2023-07-19T01:35:56.404019Z",
     "iopub.status.idle": "2023-07-19T01:35:56.423471Z",
     "shell.execute_reply": "2023-07-19T01:35:56.422424Z"
    },
    "papermill": {
     "duration": 0.044858,
     "end_time": "2023-07-19T01:35:56.425639",
     "exception": false,
     "start_time": "2023-07-19T01:35:56.380781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [173835,153662,191187,146230,104429,75860,108285,93047,146175,204591]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users = len(dense_dls.cats['user'].unique())\n",
    "user_idxs = torch.full((n_users, 1), user_index, dtype=int).cuda()\n",
    "all_users = torch.tensor(dense_dls.cats['user'].values).unique().unsqueeze(1).cuda()\n",
    "pairs = torch.cat((user_idxs, all_users), -1)\n",
    "top_10_indices = model(pairs).argsort(0)[:10]\n",
    "\n",
    "top_10_buddies = dense_dls.classes['user'][top_10_indices]\n",
    "top_10_buddies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf6fa9f",
   "metadata": {
    "papermill": {
     "duration": 0.02304,
     "end_time": "2023-07-19T01:35:56.472109",
     "exception": false,
     "start_time": "2023-07-19T01:35:56.449069",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "In this post I've covered:\n",
    "\n",
    "- how to load a dataset into fastai\n",
    "- how to take the dot product of two vectors\n",
    "- building a custom PyTorch model which inherits from pytorch's Module class and contains a forward() method and a couple of embedding layers for the input features\n",
    "- training a model on a denser subset of the data to enable faster model training\n",
    "- the role of bias and factors in the embedding matrices\n",
    "- How to get a book reccomendation for a given user\n",
    "- How to find users with similar tastes in the dataset. \n",
    "\n",
    "I was able to train a dot product based model with embedding layers on both the input features, and get book reccomendations for a given user. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfca7422",
   "metadata": {
    "papermill": {
     "duration": 0.022208,
     "end_time": "2023-07-19T01:35:56.517397",
     "exception": false,
     "start_time": "2023-07-19T01:35:56.495189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "### References\n",
    "\n",
    "http://fast.ai\n",
    "\n",
    "\n",
    "[Guo, Cheng et al. “Entity Embeddings of Categorical Variables”](https://arxiv.org/pdf/1604.06737.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 247.017596,
   "end_time": "2023-07-19T01:35:58.666754",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-07-19T01:31:51.649158",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
